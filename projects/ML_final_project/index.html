<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Menstrual Cycle Prediction Tool | Kai Holl </title> <meta name="author" content="Kai Holl"> <meta name="description" content="with ML model"> <meta name="keywords" content="portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%BC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kholl28.github.io/projects/ML_final_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Kai</span> Holl </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Menstrual Cycle Prediction Tool</h1> <p class="post-description">with ML model</p> </header> <article> <p><strong>Helpful Links</strong></p> <p><a href="https://epublications.marquette.edu/cgi/viewcontent.cgi?article=1002&amp;context=data_nfp" rel="external nofollow noopener" target="_blank">Research Article</a></p> <p><a href="https://epublications.marquette.edu/data_nfp/7/" rel="external nofollow noopener" target="_blank">Dataset</a></p> <p><a href="https://www.kaggle.com/datasets/nikitabisht/menstrual-cycle-data/data" rel="external nofollow noopener" target="_blank">Dataset (Kaggle)</a></p> <p>The present analysis’ primary goal is to create a menstrual cycle tracker that can be used to predict the day a user’s next period will start based on their demographic information and the lengths of their last two menstrual cycles.</p> <p>The user’s self-reported age and BMI will be used as secondary predictor variables that will adjust the final prediction outputted by the model.</p> <p>Previous research has indicated that age and BMI has a statistically significant relationship with menstrual cycle length, in that women in different age groups and BMI categories experience significant differences in cycle length. Thus, the model will adjust its final prediction based on this User-inputted information.</p> <p>This will be achieved through the use of a machine learning model that will be trained using data from a study which collected the menstrual cycle and demographic information of a large nationally-representative sample of women.</p> <p>User-inputted information will be piped into the final machine learning model in order to provide the user with a predicted start date of their next period.</p> <h2 id="motivation">Motivation</h2> <p>The motivation for this project is to create an accurate regression model that can be used to predict the start date of a person’s next menstrual period (the target variable) based on their last three period dates, age, and BMI (the predictor variables).</p> <p>There is no straightforward math that can be used to calculate <em>exactly</em> when someone’s next period will start. For instance, the average menstrual cycle length is around 28 days, but this varies from person to person. It’s very common to have cycles that vary by up to <em>five days</em> from one month to the next.</p> <p>There is therefore often a lot of uncertainty and anxiety that can come from not knowing when one’s next period will begin. Without using predictive models, a person’s only way to keep track of their cycles is by writing the dates that each period occured for each month in a calendar. They could then predict that their next period would start in 28 days from the start date of their most recent period, but as mentiond previously, cycle length can naturally vary by about 5 days month to month.</p> <p>Although no model can predict with 100% accuracy the exact start date of someone’s next period, identifying patterns among individual people in the lengths of each of their cycles would provide a person with more accurate, informed information, reducing uncertainty and allowing people to be more prepared.</p> <h1 id="importing-required-libraries">Importing required libraries</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># import kagglehub
</span><span class="kn">import</span> <span class="n">math</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">pip</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">scipy.stats</span> <span class="k">as</span> <span class="n">st</span>
<span class="kn">import</span> <span class="n">statistics</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">mstats</span>
<span class="kn">import</span> <span class="n">scipy</span>
<span class="kn">import</span> <span class="n">shutil</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="c1"># dates
</span><span class="kn">from</span> <span class="n">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">date</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="c1"># visualizations
</span><span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>

<span class="c1"># pre-processing
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="n">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span> <span class="c1"># Needed for IterativeImputer
</span><span class="kn">from</span> <span class="n">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span><span class="p">,</span> <span class="n">KNNImputer</span><span class="p">,</span> <span class="n">IterativeImputer</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="n">scipy.stats.mstats</span> <span class="kn">import</span> <span class="n">winsorize</span> <span class="c1"># winsorization of outliers
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span> <span class="c1"># cross-validation performance
</span><span class="kn">import</span> <span class="n">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span> <span class="c1"># Cook's distance
</span>
<span class="c1"># models
</span><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span> <span class="c1"># for control sample model
</span><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">ElasticNet</span> <span class="c1"># elasticnet regression model
</span><span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span> <span class="c1"># random forest
</span><span class="kn">import</span> <span class="n">xgboost</span> <span class="k">as</span> <span class="n">xgb</span> <span class="c1"># XGB
</span><span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span> <span class="c1"># KNN
</span>
<span class="c1"># model selection
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">learning_curve</span> <span class="c1"># testing for over/under fitting
</span>
<span class="kn">from</span> <span class="n">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># seed everything
</span><span class="k">def</span> <span class="nf">seed_everything</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
    <span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">PYTHONHASHSEED</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

</code></pre></div></div> <h1 id="data-collection">Data Collection</h1> <p>The data used for this analysis comes from a 2013 study by <a href="https://epublications.marquette.edu/cgi/viewcontent.cgi?article=1002&amp;context=data_nfp" rel="external nofollow noopener" target="_blank">Fehring et al.</a> titled “Randomized comparison of two internet-supported natural family planning methods”.</p> <p>This study collected data of the menstrual cycles of 159 anonymous American women over 12 months, with each woman having approximately 10 cycles logged. For each cycle, information such as the length of the cycle, the overall mean cycle length, estimated day of ovulation, length of menstruation, etc. is logged.</p> <p>The dataset used for this study is freely-available to the public via Marquette University’s e-Publications site (which can be accessed <a href="https://epublications.marquette.edu/data_nfp/7/" rel="external nofollow noopener" target="_blank">here</a>) and is in .csv format.</p> <p>I will now upload the dataset from GitHub as a pandas DataFrame and take a glimpse at it using the <code class="language-plaintext highlighter-rouge">head()</code> function.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import dataset
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">https://github.com/kholl28/data/raw/refs/heads/main/FedCycleData071012.csv</span><span class="sh">"</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div id="df-01c8ab57-9aa6-474a-94a0-c6faf3c61e90" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ClientID</th> <th>CycleNumber</th> <th>Group</th> <th>CycleWithPeakorNot</th> <th>ReproductiveCategory</th> <th>LengthofCycle</th> <th>MeanCycleLength</th> <th>EstimatedDayofOvulation</th> <th>LengthofLutealPhase</th> <th>FirstDayofHigh</th> <th>...</th> <th>Method</th> <th>Prevmethod</th> <th>Methoddate</th> <th>Whychart</th> <th>Nextpreg</th> <th>NextpregM</th> <th>Spousesame</th> <th>SpousesameM</th> <th>Timeattemptpreg</th> <th>BMI</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>nfp8122</td> <td>1</td> <td>0</td> <td>1</td> <td>0</td> <td>29</td> <td>27.33</td> <td>17</td> <td>12</td> <td>12</td> <td>...</td> <td>9</td> <td></td> <td></td> <td>2</td> <td>7</td> <td>7</td> <td>1</td> <td>1</td> <td>0</td> <td>21.254724111867</td> </tr> <tr> <th>1</th> <td>nfp8122</td> <td>2</td> <td>0</td> <td>1</td> <td>0</td> <td>27</td> <td></td> <td>15</td> <td>12</td> <td>13</td> <td>...</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> <tr> <th>2</th> <td>nfp8122</td> <td>3</td> <td>0</td> <td>1</td> <td>0</td> <td>29</td> <td></td> <td>15</td> <td>14</td> <td></td> <td>...</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> <tr> <th>3</th> <td>nfp8122</td> <td>4</td> <td>0</td> <td>1</td> <td>0</td> <td>27</td> <td></td> <td>15</td> <td>12</td> <td>13</td> <td>...</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> <tr> <th>4</th> <td>nfp8122</td> <td>5</td> <td>0</td> <td>1</td> <td>0</td> <td>28</td> <td></td> <td>16</td> <td>12</td> <td>12</td> <td>...</td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr> </tbody> </table> <p>5 rows × 80 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-01c8ab57-9aa6-474a-94a0-c6faf3c61e90')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-01c8ab57-9aa6-474a-94a0-c6faf3c61e90 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-01c8ab57-9aa6-474a-94a0-c6faf3c61e90');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1665, 80)
</code></pre></div></div> <p>The current uncleaned dataframe has 1665 rows and 80 columns, with each row being a cycle for a single Client (study participant) and each column containing information about the cycle and the Client it belongs to.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['ClientID', 'CycleNumber', 'Group', 'CycleWithPeakorNot',
       'ReproductiveCategory', 'LengthofCycle', 'MeanCycleLength',
       'EstimatedDayofOvulation', 'LengthofLutealPhase', 'FirstDayofHigh',
       'TotalNumberofHighDays', 'TotalHighPostPeak', 'TotalNumberofPeakDays',
       'TotalDaysofFertility', 'TotalFertilityFormula', 'LengthofMenses',
       'MeanMensesLength', 'MensesScoreDayOne', 'MensesScoreDayTwo',
       'MensesScoreDayThree', 'MensesScoreDayFour', 'MensesScoreDayFive',
       'MensesScoreDaySix', 'MensesScoreDaySeven', 'MensesScoreDayEight',
       'MensesScoreDayNine', 'MensesScoreDayTen', 'MensesScoreDay11',
       'MensesScoreDay12', 'MensesScoreDay13', 'MensesScoreDay14',
       'MensesScoreDay15', 'TotalMensesScore', 'MeanBleedingIntensity',
       'NumberofDaysofIntercourse', 'IntercourseInFertileWindow',
       'UnusualBleeding', 'PhasesBleeding', 'IntercourseDuringUnusBleed',
       'Age', 'AgeM', 'Maristatus', 'MaristatusM', 'Yearsmarried', 'Wedding',
       'Religion', 'ReligionM', 'Ethnicity', 'EthnicityM', 'Schoolyears',
       'SchoolyearsM', 'OccupationM', 'IncomeM', 'Height', 'Weight',
       'Reprocate', 'Numberpreg', 'Livingkids', 'Miscarriages', 'Abortions',
       'Medvits', 'Medvitexplain', 'Gynosurgeries', 'LivingkidsM', 'Boys',
       'Girls', 'MedvitsM', 'MedvitexplainM', 'Urosurgeries', 'Breastfeeding',
       'Method', 'Prevmethod', 'Methoddate', 'Whychart', 'Nextpreg',
       'NextpregM', 'Spousesame', 'SpousesameM', 'Timeattemptpreg', 'BMI'],
      dtype='object')
</code></pre></div></div> <h1 id="cleaning-the-dataset">Cleaning the dataset</h1> <h2 id="subsetting-dataset-columns">Subsetting dataset columns</h2> <p>The current uncleaned DataFrame, <code class="language-plaintext highlighter-rouge">df</code>, has some columns that contain information not needed for the present analysis, such as the Client’s ethnicity, marital status, or intercouse information.</p> <p>So, let’s start by cleaning this dataset to make it fit for analysis.</p> <p>More information on the columns used for the present analysis are listed below.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># specifying which columns of df we want to keep
</span><span class="n">clean_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">ClientID</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">CycleNumber</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">LengthofCycle</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BMI</span><span class="sh">"</span><span class="p">]]</span>
</code></pre></div></div> <h3 id="column-information">Column information</h3> <p><strong>The following information on column information comes directly from Fehring et al.’s 2013 study.</strong></p> <p><strong>ClientID:</strong> Randomized ID for client anonymity</p> <ul> <li>The inclusion criteria for female participants were that they needed to be between the age of 18 and 42 years, have a stated menstrual cycle length ranging between 21-42 days long, have no history of hormonal contraceptives for the past 3 months and, if post-breastfeeding, have experienced at least three cycles past weaning.</li> </ul> <p><strong>CycleNumber:</strong> study lasted 12-months for a potential total of 13 cycles tracked for each participant (one cycle approx. every month)</p> <p><strong>LengthofCycle:</strong> A menstrual cycle is defined as the time from the first day of a woman’s period to the day before her next period.</p> <ul> <li> <p>The length of the menstrual cycle varies from woman to woman, but the average is to have periods around every 28 days.</p> <p>(<a href="https://www.acog.org/womens-health/infographics/the-menstrual-cycle" rel="external nofollow noopener" target="_blank">American College of Obstetrics and Gynecologists. The Menstrual Cycle: Menstruation, Ovulation, and How Pregnancy Occurs.</a>)</p> </li> </ul> <p><strong>Demographic Variables:</strong></p> <ul> <li>Age</li> <li>Height</li> <li>Weight</li> <li>BMI (calculated from Height &amp; Weight)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">[</span><span class="sh">"</span><span class="s">ClientID</span><span class="sh">"</span><span class="p">].</span><span class="nf">nunique</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>159
</code></pre></div></div> <p>There are 159 unique Client IDs.</p> <p>Thus, the sample size for this DataFrame is 159 women between the ages of 18 and 42 years old.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1665, 7)
</code></pre></div></div> <p>There are now 1,665 rows and 7 columns in our newly cleaned dataset.</p> <h2 id="changing-class-of-variables">Changing class of variables</h2> <p>Let’s change the variable classes for all of the columns other than “ClientID” to numeric so we can conduct descriptive statistics of them.</p> <p>Let’s first see the current variable types of all the columns within <code class="language-plaintext highlighter-rouge">clean_df</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>0</th> </tr> </thead> <tbody> <tr> <th>ClientID</th> <td>object</td> </tr> <tr> <th>CycleNumber</th> <td>int64</td> </tr> <tr> <th>LengthofCycle</th> <td>int64</td> </tr> <tr> <th>Age</th> <td>object</td> </tr> <tr> <th>Height</th> <td>object</td> </tr> <tr> <th>Weight</th> <td>object</td> </tr> <tr> <th>BMI</th> <td>object</td> </tr> </tbody> </table> </div> <p><br><label><b>dtype:</b> object</label></p> <p>Now, let’s go ahead and convert all the columns besides ClientId to numeric.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">LengthofCycle</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BMI</span><span class="sh">"</span><span class="p">]</span>
<span class="n">clean_df</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span> <span class="o">=</span> <span class="n">clean_df</span><span class="p">[</span><span class="n">cols</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="sh">'</span><span class="s">coerce</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># coerce cols to numeric
</span>
<span class="n">clean_df</span><span class="p">.</span><span class="n">dtypes</span> <span class="c1"># checking work
</span></code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>0</th> </tr> </thead> <tbody> <tr> <th>ClientID</th> <td>object</td> </tr> <tr> <th>CycleNumber</th> <td>int64</td> </tr> <tr> <th>LengthofCycle</th> <td>int64</td> </tr> <tr> <th>Age</th> <td>float64</td> </tr> <tr> <th>Height</th> <td>float64</td> </tr> <tr> <th>Weight</th> <td>float64</td> </tr> <tr> <th>BMI</th> <td>float64</td> </tr> </tbody> </table> </div> <p><br><label><b>dtype:</b> object</label></p> <p>However, we don’t want the “Age” column to be coded as float class. As you can see in the below input, the values of “Age” have decimal places at the end even though this is not necessary, since “Age” is almost always considered an integer variable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">].</span><span class="nf">unique</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([36., nan, 39., 29., 26., 25., 23., 33., 30., 31., 24., 27., 35.,
       37., 32., 38., 21., 34., 22., 28., 43., 41., 40., 42.])
</code></pre></div></div> <p>Let’s use the <code class="language-plaintext highlighter-rouge">.astype()</code> function to convert “Age” to an “Int64” type.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">clean_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">Int64</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">].</span><span class="nf">unique</span><span class="p">()</span> <span class="c1"># checking work
</span></code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;IntegerArray&gt;
[  36, &lt;NA&gt;,   39,   29,   26,   25,   23,   33,   30,   31,   24,   27,   35,
   37,   32,   38,   21,   34,   22,   28,   43,   41,   40,   42]
Length: 24, dtype: Int64
</code></pre></div></div> <p>Now all of the variables in our dataset are the right variable types!</p> <h2 id="changing-empty-values-to-nan">Changing empty values to nan</h2> <p>Now, let’s see what unique values exist for all of the variables within our clean_df DataFrame.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">cols</span> <span class="ow">in</span> <span class="n">clean_df</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">cols</span><span class="si">}</span><span class="s"> : </span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="n">clean_df</span><span class="p">[</span><span class="n">cols</span><span class="p">].</span><span class="nf">unique</span><span class="p">()</span><span class="si">}</span><span class="s"> </span><span class="se">\n</span><span class="s"> </span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ClientID : 
 ['nfp8122' 'nfp8114' 'nfp8109' 'nfp8107' 'nfp8106' 'nfp8024' 'nfp8020'
 'nfp8026' 'nfp8030' 'nfp8031' 'nfp8032' 'nfp8034' 'nfp8036' 'nfp8040'
 'nfp8041' 'nfp8042' 'nfp8043' 'nfp8045' 'nfp8046' 'nfp8047' 'nfp8049'
 'nfp8050' 'nfp8051' 'nfp8057' 'nfp8058' 'nfp8060' 'nfp8062' 'nfp8063'
 'nfp8064' 'nfp8066' 'nfp8068' 'nfp8069' 'nfp8072' 'nfp8073' 'nfp8074'
 'nfp8076' 'nfp8079' 'nfp8080' 'nfp8083' 'nfp8085' 'nfp8087' 'nfp8091'
 'nfp8094' 'nfp8099' 'nfp8100' 'nfp8101' 'nfp8102' 'nfp8110' 'nfp8113'
 'nfp8116' 'nfp8123' 'nfp8124' 'nfp8129' 'nfp8131' 'nfp8133' 'nfp8137'
 'nfp8140' 'nfp8143' 'nfp8144' 'nfp8149' 'nfp8150' 'nfp8152' 'nfp8154'
 'nfp8155' 'nfp8159' 'nfp8161' 'nfp8164' 'nfp8165' 'nfp8168' 'nfp8172'
 'nfp8173' 'nfp8174' 'nfp8176' 'nfp8177' 'nfp8178' 'nfp8179' 'nfp8184'
 'nfp8186' 'nfp8187' 'nfp8188' 'nfp8189' 'nfp8190' 'nfp8192' 'nfp8193'
 'nfp8195' 'nfp8196' 'nfp8197' 'nfp8200' 'nfp8206' 'nfp8207' 'nfp8209'
 'nfp8210' 'nfp8211' 'nfp8212' 'nfp8218' 'nfp8221' 'nfp8223' 'nfp8226'
 'nfp8228' 'nfp8229' 'nfp8230' 'nfp8233' 'nfp8234' 'nfp8235' 'nfp8236'
 'nfp8237' 'nfp8238' 'nfp8240' 'nfp8242' 'nfp8244' 'nfp8246' 'nfp8247'
 'nfp8248' 'nfp8249' 'nfp8252' 'nfp8253' 'nfp8254' 'nfp8257' 'nfp8260'
 'nfp8263' 'nfp8264' 'nfp8266' 'nfp8268' 'nfp8269' 'nfp8270' 'nfp8271'
 'nfp8272' 'nfp8276' 'nfp8278' 'nfp8279' 'nfp8281' 'nfp8282' 'nfp8284'
 'nfp8286' 'nfp8288' 'nfp8289' 'nfp8290' 'nfp8292' 'nfp8293' 'nfp8294'
 'nfp8296' 'nfp8298' 'nfp8299' 'nfp8302' 'nfp8303' 'nfp8305' 'nfp8306'
 'nfp8308' 'nfp8309' 'nfp8310' 'nfp8311' 'nfp8312' 'nfp8313' 'nfp8317'
 'nfp8322' 'nfp8323' 'nfp8324' 'nfp8328' 'nfp8334'] 
 

CycleNumber : 
 [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45] 
 

LengthofCycle : 
 [29 27 28 26 24 30 25 32 31 34 23 18 33 35 41 38 36 39 37 40 21 48 22 43
 45 54 42 20 44 49 19 51] 
 

Age : 
 &lt;IntegerArray&gt;
[  36, &lt;NA&gt;,   39,   29,   26,   25,   23,   33,   30,   31,   24,   27,   35,
   37,   32,   38,   21,   34,   22,   28,   43,   41,   40,   42]
Length: 24, dtype: Int64 
 

Height : 
 [63. nan 68. 66. 71. 65. 67. 72. 69. 70. 64. 62. 61. 60. 59.] 
 

Weight : 
 [120.  nan 185. 180. 200. 150. 155. 137. 135. 136. 178. 106. 130. 187.
 168. 170. 175. 220.  95. 209. 110. 115. 141. 201. 160. 190. 145. 300.
 260. 194. 125. 179. 165. 189. 140. 122. 124. 157.   0. 268. 128. 214.
 161. 127. 138. 116. 132. 104. 195. 123. 117. 240. 152. 112. 146. 114.
 121.] 
 

BMI : 
 [21.25472411         nan 28.12608131 29.04958678 27.89129141 24.95857988
 25.79053254 21.45488973 22.46272189 21.94857668 22.62911243 24.13850309
 18.7750063  19.19554715 29.95029586 29.28514146 24.10285714 30.11085916
 27.40588104 37.75878906 16.82665659 38.96699421 19.96686391 34.7756213
 29.17724609 20.11706556 20.59570312 18.00957897 25.84558824 25.7864204
 31.47761194 24.32525952 34.74765869 26.51795005 49.91715976 21.14167966
 22.31201172 38.39109431 25.82185491 20.02633701 23.17016602 35.47918835
 25.8244898  22.86030177 28.88820018 26.62878788 37.10277778 28.33963215
 34.56477627 24.79717813 21.60896951 26.62248521 18.85207612 26.25395001
 18.79260414 22.52469388 43.25160698 19.46020761 29.85651974 36.72900391
 24.36357908 26.78887574 20.49609734 35.42454019 20.52443772 20.37681159
 21.45385742 19.36639118 21.9458897  24.12662722 22.14870825 20.54623331
 18.55945822 20.67186456 19.64848159 27.97653061 25.74462891 22.88699853
 20.4660355  20.80306122 27.45401864 18.8822314  22.59412305 21.78719008
 33.46954969 25.8398307  20.17332415 21.28222656 19.73754883 19.93383743
 21.03147763 25.29136095 20.93896484 23.49075518 30.66345271 23.56509516
 20.48283039 20.94653061 23.02595112 24.68912591 25.10216227 30.26805556
 26.62285587 22.10996327 25.10186936 22.19679931 21.92470483 22.26166667
 25.68279164 34.32617188 21.63076923 24.43636886] 
</code></pre></div></div> <p>It looks like we have quite a few missing values in the variables of our <code class="language-plaintext highlighter-rouge">clean_df</code> DataFrame.</p> <p>It also looks like our <code class="language-plaintext highlighter-rouge">Weight</code> variable has some 0 values, which should be recoded as missing. Let’s do that first.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Weight</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">clean_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Weight</span><span class="sh">'</span><span class="p">].</span><span class="nf">replace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">)</span>
</code></pre></div></div> <p>Now, let’s find the <strong>number</strong> of missing values in all the columns.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>0</th> </tr> </thead> <tbody> <tr> <th>ClientID</th> <td>0</td> </tr> <tr> <th>CycleNumber</th> <td>0</td> </tr> <tr> <th>LengthofCycle</th> <td>0</td> </tr> <tr> <th>Age</th> <td>1523</td> </tr> <tr> <th>Height</th> <td>1532</td> </tr> <tr> <th>Weight</th> <td>1532</td> </tr> <tr> <th>BMI</th> <td>1534</td> </tr> </tbody> </table> </div> <p><br><label><b>dtype:</b> int64</label></p> <p>So, that’s 4 columns with missing values and 3 columns without missing values.</p> <p>However, it makes sense that the demographic columns (“Age”, “Height”, “Weight”, “BMI) have missing values, since there is only one of these values for each Client in the dataset. That is to say, when the first row (ie., cycle) of a Client appears, this information for said Client is logged in that row, but for all subsequent cycles (rows) of that same Client, this information is left blank.</p> <p>Because of this, we only really need to worry about how many missing values are in these columns in our final dataframe which will be used to train the predictive model. We will return to this concern once the final dataframe has been created.</p> <h1 id="grouping-cyclenumber-columns-by-threes">Grouping CycleNumber columns by threes</h1> <p>As mentioned in the beginning of this analysis, the goal is to create a menstrual cycle tracker that can be used to predict the day a user’s next period will start based on information from their last two menstrual cycles.</p> <p>Therefore, in order to train the model that will make these predictions, we need to find a way to extract 3 cycles from the same Client and convert these into columns within a new DataFrame.</p> <p>Since some Clients had a larger number of reported cycle lengths than others, the number of times each Client will be repeated as a row in the new DataFrame will vary. However, each of these “triplets” will only come from a <em>single</em> Client to ensure that the model is accurately predicting menstrual cycle length using a single person as each sample.</p> <hr> <p>These “triplets” will have overlap to create a larger training and testing set to use with our model. To illustrate, here is a visual example:</p> <p>Cycle 1, Cycle 2, Cycle 3 = one triplet</p> <p>Cycle 2, Cyle 3, Cycle 4 = one triplet</p> <p>Cycle 3, Cycle 4, Cycle 5 = one triplet</p> <p>Cycle 4, Cycle 5, Cycle 6 = one triplet</p> <hr> <p>In order to pivot our <code class="language-plaintext highlighter-rouge">clean_df</code> DataFrame into a new DataFrame wherein every row is a single client (<code class="language-plaintext highlighter-rouge">ClientID</code>) and there are columns for every <code class="language-plaintext highlighter-rouge">CycleLength</code> that make up a “triplet”, we need to first create a new column within <code class="language-plaintext highlighter-rouge">clean_df</code>, <code class="language-plaintext highlighter-rouge">ClientCycleID</code>, which will contain a unique identifier for each row. This will allow us to use <code class="language-plaintext highlighter-rouge">ClientID</code> as the index in our <code class="language-plaintext highlighter-rouge">clean_df.pivot_table()</code> function.</p> <p>Each value within the newly created column <code class="language-plaintext highlighter-rouge">ClientCycleID</code> is a combination of that row’s <code class="language-plaintext highlighter-rouge">ClientID</code> and <code class="language-plaintext highlighter-rouge">CycleNumber</code> values, written as a string value.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a new column "ClientCycleID" by combining "ClientID" and "CycleNumber"
</span><span class="n">clean_df</span><span class="p">[</span><span class="sh">"</span><span class="s">ClientCycleID</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">clean_df</span><span class="p">[</span><span class="sh">"</span><span class="s">ClientID</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s">_</span><span class="sh">"</span> <span class="o">+</span> <span class="n">clean_df</span><span class="p">[</span><span class="sh">"</span><span class="s">CycleNumber</span><span class="sh">"</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>

<span class="c1"># shift newly created "ClientCycleID" column to front of clean_df DataFrame
# -----------------------------------------
</span><span class="n">first_column</span> <span class="o">=</span> <span class="n">clean_df</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="sh">"</span><span class="s">ClientCycleID</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># insert column using insert(position,column_name, first_column) function
</span><span class="n">clean_df</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="sh">"</span><span class="s">ClientCycleID</span><span class="sh">"</span><span class="p">,</span> <span class="n">first_column</span><span class="p">)</span>

<span class="n">clean_df</span>
</code></pre></div></div> <div id="df-d38a71be-6dc5-4ccf-a460-6c234f49abf2" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ClientCycleID</th> <th>ClientID</th> <th>CycleNumber</th> <th>LengthofCycle</th> <th>Age</th> <th>Height</th> <th>Weight</th> <th>BMI</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>nfp8122_1</td> <td>nfp8122</td> <td>1</td> <td>29</td> <td>36</td> <td>63.0</td> <td>120.0</td> <td>21.254724</td> </tr> <tr> <th>1</th> <td>nfp8122_2</td> <td>nfp8122</td> <td>2</td> <td>27</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>2</th> <td>nfp8122_3</td> <td>nfp8122</td> <td>3</td> <td>29</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>3</th> <td>nfp8122_4</td> <td>nfp8122</td> <td>4</td> <td>27</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>4</th> <td>nfp8122_5</td> <td>nfp8122</td> <td>5</td> <td>28</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>1660</th> <td>nfp8334_7</td> <td>nfp8334</td> <td>7</td> <td>29</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1661</th> <td>nfp8334_8</td> <td>nfp8334</td> <td>8</td> <td>28</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1662</th> <td>nfp8334_9</td> <td>nfp8334</td> <td>9</td> <td>28</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1663</th> <td>nfp8334_10</td> <td>nfp8334</td> <td>10</td> <td>40</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1664</th> <td>nfp8334_11</td> <td>nfp8334</td> <td>11</td> <td>24</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> </tbody> </table> <p>1665 rows × 8 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-d38a71be-6dc5-4ccf-a460-6c234f49abf2')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-d38a71be-6dc5-4ccf-a460-6c234f49abf2 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-d38a71be-6dc5-4ccf-a460-6c234f49abf2');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <p>Now we can create the new DataFrame mentioned previously, where every row is a single ClientID and there is a column for every triplet.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get all the unique client ids
</span><span class="n">unique_client_ids</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">clean_df</span><span class="p">[</span><span class="sh">'</span><span class="s">ClientID</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># create a new dataframe where we will store everything
</span><span class="n">new_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">ClientID</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[],</span> <span class="sh">'</span><span class="s">Cycle_1</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[],</span> <span class="sh">'</span><span class="s">Cycle_2</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[],</span> <span class="sh">'</span><span class="s">Cycle_3</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[]})</span>

<span class="c1"># loop through client ids
</span><span class="k">for</span> <span class="n">client_id</span> <span class="ow">in</span> <span class="n">unique_client_ids</span><span class="p">:</span>
    <span class="c1"># only take the portion of clean_df that belong to this client
</span>    <span class="n">t1</span> <span class="o">=</span> <span class="n">clean_df</span><span class="p">[</span><span class="n">clean_df</span><span class="p">[</span><span class="sh">'</span><span class="s">ClientID</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">client_id</span><span class="p">]</span>
    <span class="c1"># only take these two columns
</span>    <span class="n">t1</span> <span class="o">=</span> <span class="n">t1</span><span class="p">[[</span><span class="sh">'</span><span class="s">ClientID</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">LengthofCycle</span><span class="sh">'</span><span class="p">]]</span>

    <span class="c1"># loop through all the rows except last two
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">t1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
        <span class="c1"># for every row, get that row and the two rows after that
</span>        <span class="n">t2</span> <span class="o">=</span> <span class="n">t1</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">)].</span><span class="nf">copy</span><span class="p">()</span>
        <span class="c1"># create a new column
</span>        <span class="n">t2</span><span class="p">[</span><span class="sh">'</span><span class="s">CycleID</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Cycle_1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cycle_2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cycle_3</span><span class="sh">'</span><span class="p">]</span>
        <span class="c1"># reshape
</span>        <span class="n">t3</span> <span class="o">=</span> <span class="n">t2</span><span class="p">.</span><span class="nf">pivot</span><span class="p">(</span><span class="n">index</span> <span class="o">=</span> <span class="sh">'</span><span class="s">ClientID</span><span class="sh">'</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="sh">'</span><span class="s">CycleID</span><span class="sh">'</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="sh">'</span><span class="s">LengthofCycle</span><span class="sh">'</span><span class="p">)</span>
        <span class="c1"># add to the dataframe
</span>        <span class="n">new_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">new_df</span><span class="p">,</span> <span class="n">t3</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">()],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># check out
</span><span class="n">new_df</span>
</code></pre></div></div> <div id="df-4187519c-1a82-4451-a05c-e46939079da4" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ClientID</th> <th>Cycle_1</th> <th>Cycle_2</th> <th>Cycle_3</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>nfp8294</td> <td>37.0</td> <td>40.0</td> <td>39.0</td> </tr> <tr> <th>0</th> <td>nfp8294</td> <td>40.0</td> <td>39.0</td> <td>30.0</td> </tr> <tr> <th>0</th> <td>nfp8294</td> <td>39.0</td> <td>30.0</td> <td>29.0</td> </tr> <tr> <th>0</th> <td>nfp8294</td> <td>30.0</td> <td>29.0</td> <td>35.0</td> </tr> <tr> <th>0</th> <td>nfp8294</td> <td>29.0</td> <td>35.0</td> <td>29.0</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>0</th> <td>nfp8246</td> <td>28.0</td> <td>28.0</td> <td>31.0</td> </tr> <tr> <th>0</th> <td>nfp8159</td> <td>38.0</td> <td>38.0</td> <td>42.0</td> </tr> <tr> <th>0</th> <td>nfp8159</td> <td>38.0</td> <td>42.0</td> <td>37.0</td> </tr> <tr> <th>0</th> <td>nfp8159</td> <td>42.0</td> <td>37.0</td> <td>30.0</td> </tr> <tr> <th>0</th> <td>nfp8159</td> <td>37.0</td> <td>30.0</td> <td>38.0</td> </tr> </tbody> </table> <p>1358 rows × 4 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-4187519c-1a82-4451-a05c-e46939079da4')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-4187519c-1a82-4451-a05c-e46939079da4 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-4187519c-1a82-4451-a05c-e46939079da4');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <p>Success! Let’s look at the shape of our <code class="language-plaintext highlighter-rouge">new_df</code> dataframe.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1358, 4)
</code></pre></div></div> <p>Our new DataFrame, <code class="language-plaintext highlighter-rouge">new_df</code>, which contains the triplet CycleLengths, has 1,358 rows and 4 columns.</p> <h2 id="adding-secondary-predictor-variables">Adding secondary predictor variables</h2> <p>Since we want to use the demographic variables <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Height</code>, <code class="language-plaintext highlighter-rouge">Weight</code>, and <code class="language-plaintext highlighter-rouge">BMI</code> as secondary variables for menstrual cycle prediction, let’s create a new DataFrame, <code class="language-plaintext highlighter-rouge">dems</code>, which contains only the <code class="language-plaintext highlighter-rouge">ClientID</code> and demographic columns of <code class="language-plaintext highlighter-rouge">clean_df</code>.</p> <p>We will need to preserve the ClientID column to use as a key during merging.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dems</span> <span class="o">=</span> <span class="n">clean_df</span><span class="p">[[</span><span class="sh">"</span><span class="s">ClientID</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BMI</span><span class="sh">"</span><span class="p">]]</span>

<span class="c1"># convert to pandas DataFrame
</span><span class="n">dems</span> <span class="o">=</span> <span class="n">dems</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">()</span>

<span class="n">dems</span>
</code></pre></div></div> <div id="df-7a3dd8f0-3ecf-4b6e-a1f4-ae8336567051" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>index</th> <th>ClientID</th> <th>Age</th> <th>Height</th> <th>Weight</th> <th>BMI</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0</td> <td>nfp8122</td> <td>36</td> <td>63.0</td> <td>120.0</td> <td>21.254724</td> </tr> <tr> <th>1</th> <td>1</td> <td>nfp8122</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>2</th> <td>2</td> <td>nfp8122</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>3</th> <td>3</td> <td>nfp8122</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>4</th> <td>4</td> <td>nfp8122</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>1660</th> <td>1660</td> <td>nfp8334</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1661</th> <td>1661</td> <td>nfp8334</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1662</th> <td>1662</td> <td>nfp8334</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1663</th> <td>1663</td> <td>nfp8334</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1664</th> <td>1664</td> <td>nfp8334</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> </tbody> </table> <p>1665 rows × 6 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-7a3dd8f0-3ecf-4b6e-a1f4-ae8336567051')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-7a3dd8f0-3ecf-4b6e-a1f4-ae8336567051 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-7a3dd8f0-3ecf-4b6e-a1f4-ae8336567051');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">].</span><span class="nf">count</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.int64(142)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clean_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.int64(1523)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dems</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">].</span><span class="nf">count</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.int64(142)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dems</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.int64(1523)
</code></pre></div></div> <p>During the creation of this dems DataFrame, we will drop rows where both <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Height</code>, <code class="language-plaintext highlighter-rouge">Weight</code>, <em>and</em> <code class="language-plaintext highlighter-rouge">BMI</code> have missing values, since, as mentioned previously, demographic information is only listed in a single row for each Client.</p> <p>This will ensure that only one row exists for each Client in our final dataframe.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># # Drop rows where both 'Age', 'Height', and 'Weight' are missing
</span><span class="n">dems</span> <span class="o">=</span> <span class="n">dems</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Height</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Weight</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">BMI</span><span class="sh">'</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># checking work
# --------------
# dems.head()
# dems.shape # 1665, 4
</span>
<span class="n">dems</span>
</code></pre></div></div> <div id="df-81a1f976-e476-41df-a6b8-b1736995831c" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>index</th> <th>ClientID</th> <th>Age</th> <th>Height</th> <th>Weight</th> <th>BMI</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>0</td> <td>nfp8122</td> <td>36</td> <td>63.0</td> <td>120.0</td> <td>21.254724</td> </tr> <tr> <th>45</th> <td>45</td> <td>nfp8114</td> <td>39</td> <td>68.0</td> <td>185.0</td> <td>28.126081</td> </tr> <tr> <th>47</th> <td>47</td> <td>nfp8109</td> <td>29</td> <td>66.0</td> <td>180.0</td> <td>29.049587</td> </tr> <tr> <th>50</th> <td>50</td> <td>nfp8107</td> <td>26</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>58</th> <td>58</td> <td>nfp8106</td> <td>25</td> <td>71.0</td> <td>200.0</td> <td>27.891291</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>1345</th> <td>1345</td> <td>nfp8288</td> <td>30</td> <td>70.0</td> <td>195.0</td> <td>27.976531</td> </tr> <tr> <th>1348</th> <td>1348</td> <td>nfp8289</td> <td>40</td> <td>65.0</td> <td>135.0</td> <td>22.462722</td> </tr> <tr> <th>1380</th> <td>1380</td> <td>nfp8290</td> <td>33</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1393</th> <td>1393</td> <td>nfp8292</td> <td>34</td> <td>66.0</td> <td>150.0</td> <td>NaN</td> </tr> <tr> <th>1406</th> <td>1406</td> <td>nfp8293</td> <td>23</td> <td>63.0</td> <td>110.0</td> <td>NaN</td> </tr> </tbody> </table> <p>142 rows × 6 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-81a1f976-e476-41df-a6b8-b1736995831c')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-81a1f976-e476-41df-a6b8-b1736995831c button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-81a1f976-e476-41df-a6b8-b1736995831c');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dems</span><span class="p">[</span><span class="sh">'</span><span class="s">ClientID</span><span class="sh">'</span><span class="p">].</span><span class="nf">nunique</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>138
</code></pre></div></div> <p>It looks like our sample of women was reduced from 159 to 138 when we subsetted <code class="language-plaintext highlighter-rouge">dems</code> to not include rows where all of the demographic columns had missing values.</p> <p>From this, we can deduce that 23 of the women in the original sample did not have any demographic information recorded when Fehring et al. conducted the study.</p> <p>Since it would be difficult to attempt to use an imputer to fill in missing information for four columns for each of these 23 women, it’s best to just remove them fully from the study and use the 138 women we do have more complete data on.</p> <p>Now, let’s merge dems and new_df together into a single DataFrame.</p> <p>We will be using a left merge in order to keep every row of new_df and discard any rows in dems that do not have a matching ClientID in new_df.</p> <p>This new dataframe will contain the menstrual cycle triplets and secondary predictor variables of each client.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span> <span class="o">=</span> <span class="n">new_df</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span><span class="n">dems</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">ClientID</span><span class="sh">"</span><span class="p">],</span> <span class="n">how</span> <span class="o">=</span> <span class="sh">"</span><span class="s">left</span><span class="sh">"</span><span class="p">)</span>

<span class="n">final_df</span>
</code></pre></div></div> <div id="df-5aa7457d-f3b3-403c-a697-e3d483a9c82f" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ClientID</th> <th>Cycle_1</th> <th>Cycle_2</th> <th>Cycle_3</th> <th>index</th> <th>Age</th> <th>Height</th> <th>Weight</th> <th>BMI</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>nfp8294</td> <td>37.0</td> <td>40.0</td> <td>39.0</td> <td>NaN</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1</th> <td>nfp8294</td> <td>40.0</td> <td>39.0</td> <td>30.0</td> <td>NaN</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>2</th> <td>nfp8294</td> <td>39.0</td> <td>30.0</td> <td>29.0</td> <td>NaN</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>3</th> <td>nfp8294</td> <td>30.0</td> <td>29.0</td> <td>35.0</td> <td>NaN</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>4</th> <td>nfp8294</td> <td>29.0</td> <td>35.0</td> <td>29.0</td> <td>NaN</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>1377</th> <td>nfp8246</td> <td>28.0</td> <td>28.0</td> <td>31.0</td> <td>1145.0</td> <td>22</td> <td>62.0</td> <td>112.0</td> <td>20.482830</td> </tr> <tr> <th>1378</th> <td>nfp8159</td> <td>38.0</td> <td>38.0</td> <td>42.0</td> <td>711.0</td> <td>33</td> <td>66.0</td> <td>268.0</td> <td>43.251607</td> </tr> <tr> <th>1379</th> <td>nfp8159</td> <td>38.0</td> <td>42.0</td> <td>37.0</td> <td>711.0</td> <td>33</td> <td>66.0</td> <td>268.0</td> <td>43.251607</td> </tr> <tr> <th>1380</th> <td>nfp8159</td> <td>42.0</td> <td>37.0</td> <td>30.0</td> <td>711.0</td> <td>33</td> <td>66.0</td> <td>268.0</td> <td>43.251607</td> </tr> <tr> <th>1381</th> <td>nfp8159</td> <td>37.0</td> <td>30.0</td> <td>38.0</td> <td>711.0</td> <td>33</td> <td>66.0</td> <td>268.0</td> <td>43.251607</td> </tr> </tbody> </table> <p>1382 rows × 9 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-5aa7457d-f3b3-403c-a697-e3d483a9c82f')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-5aa7457d-f3b3-403c-a697-e3d483a9c82f button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-5aa7457d-f3b3-403c-a697-e3d483a9c82f');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <p>I will also go ahead and drop the “index” column that was created from the merge, as it is not necessary for analysis.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">"</span><span class="s">index</span><span class="sh">"</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <h1 id="train-test-split">train test split</h1> <p>We will use <code class="language-plaintext highlighter-rouge">train_test_split()</code> to split our data into a training set and test set.</p> <p>Since our dataset is relatively small (1,382 samples), we will want to use a slightly larger test size to ensure that our test set has enough data for reliable evaluation.</p> <p>Thus, we will set the train_size parameter to 0.7 in order to extract 30% of the dataset for the testing set.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">seed_everything</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">Cycle_1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cycle_2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Height</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Weight</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">BMI</span><span class="sh">'</span><span class="p">]]</span> <span class="c1"># denote all predictos with uppercase X
</span><span class="n">y</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Cycle_3</span><span class="sh">'</span><span class="p">]</span> <span class="c1"># denote target (outcome variable) with lowercase Y
</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="c1"># test_size = 30% should go to the test set
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span>
</code></pre></div></div> <div id="df-46c5bdba-e8b8-4eeb-9275-23c42284b071" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Cycle_1</th> <th>Cycle_2</th> <th>Age</th> <th>Height</th> <th>Weight</th> <th>BMI</th> </tr> </thead> <tbody> <tr> <th>482</th> <td>27.0</td> <td>29.0</td> <td>32</td> <td>68.0</td> <td>135.0</td> <td>20.524438</td> </tr> <tr> <th>59</th> <td>23.0</td> <td>25.0</td> <td>37</td> <td>64.0</td> <td>130.0</td> <td>22.312012</td> </tr> <tr> <th>405</th> <td>27.0</td> <td>34.0</td> <td>32</td> <td>65.0</td> <td>152.0</td> <td>25.291361</td> </tr> <tr> <th>464</th> <td>40.0</td> <td>33.0</td> <td>22</td> <td>59.0</td> <td>130.0</td> <td>26.253950</td> </tr> <tr> <th>1303</th> <td>33.0</td> <td>27.0</td> <td>25</td> <td>68.0</td> <td>135.0</td> <td>20.524438</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>1095</th> <td>24.0</td> <td>24.0</td> <td>36</td> <td>63.0</td> <td>140.0</td> <td>24.797178</td> </tr> <tr> <th>1130</th> <td>27.0</td> <td>28.0</td> <td>31</td> <td>68.0</td> <td>146.0</td> <td>22.196799</td> </tr> <tr> <th>1294</th> <td>42.0</td> <td>43.0</td> <td>32</td> <td>65.0</td> <td>161.0</td> <td>26.788876</td> </tr> <tr> <th>860</th> <td>25.0</td> <td>27.0</td> <td>35</td> <td>66.0</td> <td>120.0</td> <td>19.366391</td> </tr> <tr> <th>1126</th> <td>35.0</td> <td>28.0</td> <td>31</td> <td>68.0</td> <td>146.0</td> <td>22.196799</td> </tr> </tbody> </table> <p>967 rows × 6 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-46c5bdba-e8b8-4eeb-9275-23c42284b071')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-46c5bdba-e8b8-4eeb-9275-23c42284b071 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-46c5bdba-e8b8-4eeb-9275-23c42284b071');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <p><code class="language-plaintext highlighter-rouge">X_train</code> has 967 rows and 6 columns.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_test</span>
</code></pre></div></div> <div id="df-f30c099f-64a4-457e-9f84-7e7a4524b77b" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Cycle_1</th> <th>Cycle_2</th> <th>Age</th> <th>Height</th> <th>Weight</th> <th>BMI</th> </tr> </thead> <tbody> <tr> <th>309</th> <td>25.0</td> <td>26.0</td> <td>29</td> <td>69.0</td> <td>138.0</td> <td>20.376812</td> </tr> <tr> <th>741</th> <td>36.0</td> <td>28.0</td> <td>31</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>265</th> <td>26.0</td> <td>28.0</td> <td>36</td> <td>63.0</td> <td>120.0</td> <td>21.254724</td> </tr> <tr> <th>823</th> <td>28.0</td> <td>29.0</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>778</th> <td>27.0</td> <td>25.0</td> <td>33</td> <td>65.0</td> <td>155.0</td> <td>25.790533</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>506</th> <td>29.0</td> <td>33.0</td> <td>25</td> <td>67.0</td> <td>170.0</td> <td>26.622856</td> </tr> <tr> <th>985</th> <td>25.0</td> <td>28.0</td> <td>34</td> <td>66.0</td> <td>150.0</td> <td>NaN</td> </tr> <tr> <th>266</th> <td>28.0</td> <td>28.0</td> <td>36</td> <td>63.0</td> <td>120.0</td> <td>21.254724</td> </tr> <tr> <th>327</th> <td>34.0</td> <td>30.0</td> <td>28</td> <td>60.0</td> <td>190.0</td> <td>37.102778</td> </tr> <tr> <th>348</th> <td>29.0</td> <td>27.0</td> <td>31</td> <td>64.0</td> <td>170.0</td> <td>29.177246</td> </tr> </tbody> </table> <p>415 rows × 6 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-f30c099f-64a4-457e-9f84-7e7a4524b77b')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-f30c099f-64a4-457e-9f84-7e7a4524b77b button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-f30c099f-64a4-457e-9f84-7e7a4524b77b');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <p><code class="language-plaintext highlighter-rouge">X_test</code> has 416 rows and 6 columns.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>np.int64(0)
</code></pre></div></div> <p>Since <code class="language-plaintext highlighter-rouge">Cycle_3</code> had no missing values in our <code class="language-plaintext highlighter-rouge">final_df</code> dataframe, our y_train dataset has no missing values either!</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Cycle_3</th> </tr> </thead> <tbody> <tr> <th>482</th> <td>28.0</td> </tr> <tr> <th>59</th> <td>25.0</td> </tr> <tr> <th>405</th> <td>32.0</td> </tr> <tr> <th>464</th> <td>54.0</td> </tr> <tr> <th>1303</th> <td>29.0</td> </tr> <tr> <th>...</th> <td>...</td> </tr> <tr> <th>1095</th> <td>23.0</td> </tr> <tr> <th>1130</th> <td>30.0</td> </tr> <tr> <th>1294</th> <td>31.0</td> </tr> <tr> <th>860</th> <td>26.0</td> </tr> <tr> <th>1126</th> <td>30.0</td> </tr> </tbody> </table> <p>967 rows × 1 columns</p> </div> <p><br><label><b>dtype:</b> float64</label></p> <p><code class="language-plaintext highlighter-rouge">y_train</code> has 967 rows and 1 column, <code class="language-plaintext highlighter-rouge">Cycle_3</code>, our target variable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_test</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Cycle_3</th> </tr> </thead> <tbody> <tr> <th>309</th> <td>26.0</td> </tr> <tr> <th>741</th> <td>32.0</td> </tr> <tr> <th>265</th> <td>28.0</td> </tr> <tr> <th>823</th> <td>27.0</td> </tr> <tr> <th>778</th> <td>24.0</td> </tr> <tr> <th>...</th> <td>...</td> </tr> <tr> <th>506</th> <td>31.0</td> </tr> <tr> <th>985</th> <td>26.0</td> </tr> <tr> <th>266</th> <td>24.0</td> </tr> <tr> <th>327</th> <td>29.0</td> </tr> <tr> <th>348</th> <td>29.0</td> </tr> </tbody> </table> <p>415 rows × 1 columns</p> </div> <p><br><label><b>dtype:</b> float64</label></p> <p><code class="language-plaintext highlighter-rouge">y_test</code> has 415 rows and 1 column, <code class="language-plaintext highlighter-rouge">Cycle_3</code>, our target variable.</p> <h1 id="exploratory-data-analysis">Exploratory Data Analysis</h1> <h2 id="data-structure">Data structure</h2> <p>Let’s see the structure of our final dataset, final_df.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span>
</code></pre></div></div> <div id="df-f500abf6-bfa6-42b3-a084-a26b11d94b11" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ClientID</th> <th>Cycle_1</th> <th>Cycle_2</th> <th>Cycle_3</th> <th>Age</th> <th>Height</th> <th>Weight</th> <th>BMI</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>nfp8294</td> <td>37.0</td> <td>40.0</td> <td>39.0</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>1</th> <td>nfp8294</td> <td>40.0</td> <td>39.0</td> <td>30.0</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>2</th> <td>nfp8294</td> <td>39.0</td> <td>30.0</td> <td>29.0</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>3</th> <td>nfp8294</td> <td>30.0</td> <td>29.0</td> <td>35.0</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>4</th> <td>nfp8294</td> <td>29.0</td> <td>35.0</td> <td>29.0</td> <td>&lt;NA&gt;</td> <td>NaN</td> <td>NaN</td> <td>NaN</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>1377</th> <td>nfp8246</td> <td>28.0</td> <td>28.0</td> <td>31.0</td> <td>22</td> <td>62.0</td> <td>112.0</td> <td>20.482830</td> </tr> <tr> <th>1378</th> <td>nfp8159</td> <td>38.0</td> <td>38.0</td> <td>42.0</td> <td>33</td> <td>66.0</td> <td>268.0</td> <td>43.251607</td> </tr> <tr> <th>1379</th> <td>nfp8159</td> <td>38.0</td> <td>42.0</td> <td>37.0</td> <td>33</td> <td>66.0</td> <td>268.0</td> <td>43.251607</td> </tr> <tr> <th>1380</th> <td>nfp8159</td> <td>42.0</td> <td>37.0</td> <td>30.0</td> <td>33</td> <td>66.0</td> <td>268.0</td> <td>43.251607</td> </tr> <tr> <th>1381</th> <td>nfp8159</td> <td>37.0</td> <td>30.0</td> <td>38.0</td> <td>33</td> <td>66.0</td> <td>268.0</td> <td>43.251607</td> </tr> </tbody> </table> <p>1382 rows × 8 columns</p> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-f500abf6-bfa6-42b3-a084-a26b11d94b11')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-f500abf6-bfa6-42b3-a084-a26b11d94b11 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-f500abf6-bfa6-42b3-a084-a26b11d94b11');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1382, 8)
</code></pre></div></div> <p>Our final dataset that will be used for analysis, final_df, has 1,382 rows and 8 columns.</p> <p>Each row represents a grouping of three cycle lengths for a single participant, as well as the age, height, weight, and BMI of that participant.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">final_df</span><span class="p">.</span><span class="n">dtypes</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>0</th> </tr> </thead> <tbody> <tr> <th>ClientID</th> <td>object</td> </tr> <tr> <th>Cycle_1</th> <td>float64</td> </tr> <tr> <th>Cycle_2</th> <td>float64</td> </tr> <tr> <th>Cycle_3</th> <td>float64</td> </tr> <tr> <th>Age</th> <td>Int64</td> </tr> <tr> <th>Height</th> <td>float64</td> </tr> <tr> <th>Weight</th> <td>float64</td> </tr> <tr> <th>BMI</th> <td>float64</td> </tr> </tbody> </table> </div> <p><br><label><b>dtype:</b> object</label></p> <p>Of the 8 columns, all are numeric except for <code class="language-plaintext highlighter-rouge">ClientID</code>, which is categorical. This column contains unique identification numbers that are used to identify each client in the study.</p> <p><code class="language-plaintext highlighter-rouge">ClientID</code> will not be used as a predictor variable in the final model, but was useful in helping to group the cycle columns by threes for our final_df.</p> <h2 id="distribution-of-cycle_3">Distribution of cycle_3</h2> <p>Our target variable is <code class="language-plaintext highlighter-rouge">Cycle_3</code>, which is the length of the third menstrual cycle (for the client, this is the length of their current cycle).</p> <p>We should visualise the distribution of <code class="language-plaintext highlighter-rouge">Cycle_3</code> to see if it looks like any common probability distributions. This will help us understand the range and frequency of potential outcomes from the final model and help us any potential biases in our data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">final_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Cycle_3</span><span class="sh">"</span><span class="p">],</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">37</span><span class="p">,</span> <span class="n">kde</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="c1"># reduced number of bins until there were no empty spaces in plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Cycle Length (days)</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># change x-axis label
</span><span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Frequency</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># change y-axis label
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Menstrual Cycle 3 Length Distribution</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># change title
</span><span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><img src="ML_final_project_files/ML_final_project_85_0.png" alt="png"></p> <p>From the above plot, it appears as though <code class="language-plaintext highlighter-rouge">Cycle_3</code> has a <strong>right-skewed</strong> distribution, meaning that the majority of the data is located on the left side of the graph, and the mean is greater than the median.</p> <p>Most values are concentrated between 25 and 32 days, although the tail stretches to the right, indicating that some women in the sample have cycle lengths up to 50 or more days.</p> <p>In other words, on average, most of the women in the sample have menstrual cycles that are shorter than longer. A small number of individuals had significantly longer cycles, but are outliers in the data.</p> <p>Let’s look at the mean, mode, minimum, and maximum length of <code class="language-plaintext highlighter-rouge">Cycle_3</code> in <code class="language-plaintext highlighter-rouge">final_df</code> in order to understand our target variable more.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The average length of Cycle 3 of the entire sample is</span><span class="sh">"</span><span class="p">,</span> <span class="nf">round</span><span class="p">(</span><span class="n">final_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Cycle_3</span><span class="sh">"</span><span class="p">].</span><span class="nf">mean</span><span class="p">(),</span> <span class="mi">2</span><span class="p">),</span> <span class="sh">"</span><span class="s">days.</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The most common length of Cycle 3 of the entire sample is</span><span class="sh">"</span><span class="p">,</span> <span class="nf">round</span><span class="p">(</span><span class="n">statistics</span><span class="p">.</span><span class="nf">mode</span><span class="p">(</span><span class="n">final_df</span><span class="p">[</span><span class="sh">"</span><span class="s">Cycle_3</span><span class="sh">"</span><span class="p">]),</span> <span class="mi">2</span><span class="p">),</span> <span class="sh">"</span><span class="s">days.</span><span class="sh">"</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The shortest length of Cycle 3 in the dataset is</span><span class="sh">"</span><span class="p">,</span> <span class="n">final_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Cycle_3</span><span class="sh">'</span><span class="p">].</span><span class="nf">min</span><span class="p">(),</span> <span class="sh">"</span><span class="s">days.</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The longest length of Cycle 3 in the dataset is</span><span class="sh">"</span><span class="p">,</span> <span class="n">final_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Cycle_3</span><span class="sh">'</span><span class="p">].</span><span class="nf">max</span><span class="p">(),</span> <span class="sh">"</span><span class="s">days.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The average length of Cycle 3 of the entire sample is 29.14 days.
The most common length of Cycle 3 of the entire sample is 28.0 days.
The shortest length of Cycle 3 in the dataset is 18.0 days.
The longest length of Cycle 3 in the dataset is 54.0 days.
</code></pre></div></div> <p>Compared to the aforementioned information reported by the American College of Obstetrics and Gynecologists that found the average menstrual cycle to be around 28 days long, the average length of <code class="language-plaintext highlighter-rouge">Cycle_3</code> in the current sample is slightly longer by about 1.15 days.</p> <p>However, the most common length of <code class="language-plaintext highlighter-rouge">Cycle_3</code> for our dataset was 28 days, which aligns with the previous research.</p> <p>As the above histogram illustrates, the distribution of <code class="language-plaintext highlighter-rouge">Cycle_3</code> is right-skewed, with some participants having irregular lengths of 50 or more days. The longest length was 54 days, which is significantly longer than average.</p> <p>Outlier values like this one are pulling the mean to the right so it is greater (longer) than the median length.</p> <p>However, a mean length of 29.14 days is not significantly longer than the median of 28 days. There are natural deviations in cycle length for each individual month to month. Thus, this difference is likely due to natural deviations from the mean.</p> <p>(Source: <a href="https://hsph.harvard.edu/research/apple-womens-health-study/study-updates/menstrual-cycles-today-how-menstrual-cycles-vary-by-age-weight-race-and-ethnicity/" rel="external nofollow noopener" target="_blank">Harvard T.H. Chan School of Public Health, Menstrual cycles today</a>)</p> <p>However, further analysis with be conducted to explore these outliers and whether they are cause for concern when creating our final model.</p> <h2 id="missing-values">Missing values</h2> <p>As we saw earlier, our demographic columns are the columns with missing values.</p> <p>One thing we can do to reduce the number of missing values in <code class="language-plaintext highlighter-rouge">BMI</code> without using an imputer is by simply calculating the BMI for rows that have values for <code class="language-plaintext highlighter-rouge">Height</code> and <code class="language-plaintext highlighter-rouge">Weight</code>.</p> <p>Let’s use this method for both the training and set sets. Since our y_train and y_test only contain <code class="language-plaintext highlighter-rouge">Cycle_3</code>, which contains no missing values, we can just focus on using this method for <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code>.</p> <p>We can then look at the number of missing values for <code class="language-plaintext highlighter-rouge">BMI</code> for both dataframes before and after using this method.</p> <h3 id="training-set">training set</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># before
</span><span class="n">missing_bmi_count</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="sh">'</span><span class="s">BMI</span><span class="sh">'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of missing values for BMI before imputation: </span><span class="si">{</span><span class="n">missing_bmi_count</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of missing values for BMI before imputation: 209
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">[</span><span class="sh">"</span><span class="s">BMI</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nf">round</span><span class="p">((</span><span class="n">X_train</span><span class="p">[</span><span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">703</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># after
</span><span class="n">missing_bmi_count</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="sh">'</span><span class="s">BMI</span><span class="sh">'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of missing values for BMI after imputation: </span><span class="si">{</span><span class="n">missing_bmi_count</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of missing values for BMI after imputation: 205
</code></pre></div></div> <p>So, it looks like by using this imputation strategy, we filled in 6 missing values in <code class="language-plaintext highlighter-rouge">X_train</code> for <code class="language-plaintext highlighter-rouge">BMI</code> just by using the values of <code class="language-plaintext highlighter-rouge">Height</code> and <code class="language-plaintext highlighter-rouge">Weight</code> that we already had in our dataset!</p> <p>Now, let’s look at the <em>proportion</em> of missing values for each column in our training set, as well as the actual <em>count</em> of missing values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># training set
</span>
<span class="c1"># concatenate X_train and y_train into a single DataFrame
</span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">null</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">().</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">null_per</span> <span class="o">=</span> <span class="p">((</span><span class="n">train</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])).</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">*</span><span class="mf">100.</span>
<span class="n">null_values</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">"</span><span class="s">Column Name</span><span class="sh">"</span><span class="p">:</span> <span class="n">null</span><span class="p">.</span><span class="n">index</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">Total Number of Missing Values</span><span class="sh">"</span><span class="p">:</span> <span class="n">null</span><span class="p">.</span><span class="n">values</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">Percentage NA</span><span class="sh">"</span><span class="p">:</span> <span class="n">null_per</span><span class="p">.</span><span class="n">values</span>
<span class="p">})</span>

<span class="n">null_values</span>
</code></pre></div></div> <div id="df-79d22303-c26b-4b47-8472-84be6de24f98" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Column Name</th> <th>Total Number of Missing Values</th> <th>Percentage NA</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>BMI</td> <td>205</td> <td>21.199586</td> </tr> <tr> <th>1</th> <td>Weight</td> <td>205</td> <td>21.199586</td> </tr> <tr> <th>2</th> <td>Height</td> <td>205</td> <td>21.199586</td> </tr> <tr> <th>3</th> <td>Age</td> <td>157</td> <td>16.235781</td> </tr> <tr> <th>4</th> <td>Cycle_1</td> <td>0</td> <td>0.000000</td> </tr> <tr> <th>5</th> <td>Cycle_2</td> <td>0</td> <td>0.000000</td> </tr> <tr> <th>6</th> <td>Cycle_3</td> <td>0</td> <td>0.000000</td> </tr> </tbody> </table> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-79d22303-c26b-4b47-8472-84be6de24f98')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-79d22303-c26b-4b47-8472-84be6de24f98 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-79d22303-c26b-4b47-8472-84be6de24f98');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <p>Our demographic variables <code class="language-plaintext highlighter-rouge">BMI</code>, <code class="language-plaintext highlighter-rouge">Height</code>, <code class="language-plaintext highlighter-rouge">Weight</code>, and <code class="language-plaintext highlighter-rouge">Age</code> are the columns with missing values in our training set.</p> <p><code class="language-plaintext highlighter-rouge">BMI</code>, <code class="language-plaintext highlighter-rouge">Height</code>, and <code class="language-plaintext highlighter-rouge">Weight</code> all have approximately 20% of their values set to missing. <code class="language-plaintext highlighter-rouge">Age</code> has about 16% of its values missing.</p> <h3 id="test-set">test set</h3> <p>Let’s first use the BMI calculation strategy with our test set now too!</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># before
</span><span class="n">missing_bmi_count</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="sh">'</span><span class="s">BMI</span><span class="sh">'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of missing values for BMI before imputation: </span><span class="si">{</span><span class="n">missing_bmi_count</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of missing values for BMI before imputation: 99
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_test</span><span class="p">[</span><span class="sh">"</span><span class="s">BMI</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nf">round</span><span class="p">((</span><span class="n">X_test</span><span class="p">[</span><span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">703</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># after
</span><span class="n">missing_bmi_count</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="sh">'</span><span class="s">BMI</span><span class="sh">'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Number of missing values for BMI after imputation: </span><span class="si">{</span><span class="n">missing_bmi_count</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of missing values for BMI after imputation: 91
</code></pre></div></div> <p>Using the BMI calculation strategy filled in 6 values for <code class="language-plaintext highlighter-rouge">X_test</code>!</p> <p>Now for the proportion and count of missing values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test set
</span>
<span class="c1"># concatenate X_test and y_test into a single DataFrame
</span><span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">null</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">().</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">null_per</span> <span class="o">=</span> <span class="p">((</span><span class="n">test</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])).</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">*</span><span class="mf">100.</span>
<span class="n">null_values</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">"</span><span class="s">Column Name</span><span class="sh">"</span><span class="p">:</span> <span class="n">null</span><span class="p">.</span><span class="n">index</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">Total Number of Missing Values</span><span class="sh">"</span><span class="p">:</span> <span class="n">null</span><span class="p">.</span><span class="n">values</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">Percentage NA</span><span class="sh">"</span><span class="p">:</span> <span class="n">null_per</span><span class="p">.</span><span class="n">values</span>
<span class="p">})</span>

<span class="n">null_values</span>
</code></pre></div></div> <div id="df-4097d005-8640-4a5e-84b9-ffad21cf2071" class="colab-df-container"> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Column Name</th> <th>Total Number of Missing Values</th> <th>Percentage NA</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>BMI</td> <td>91</td> <td>21.927711</td> </tr> <tr> <th>1</th> <td>Weight</td> <td>91</td> <td>21.927711</td> </tr> <tr> <th>2</th> <td>Height</td> <td>91</td> <td>21.927711</td> </tr> <tr> <th>3</th> <td>Age</td> <td>68</td> <td>16.385542</td> </tr> <tr> <th>4</th> <td>Cycle_1</td> <td>0</td> <td>0.000000</td> </tr> <tr> <th>5</th> <td>Cycle_2</td> <td>0</td> <td>0.000000</td> </tr> <tr> <th>6</th> <td>Cycle_3</td> <td>0</td> <td>0.000000</td> </tr> </tbody> </table> </div> <div class="colab-df-buttons"> <div class="colab-df-container"> <button class="colab-df-convert" onclick="convertToInteractive('df-4097d005-8640-4a5e-84b9-ffad21cf2071')" title="Convert this dataframe to an interactive table." style="display:none;"> <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960"> <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path> </svg> </button> <style>.colab-df-container{display:flex;gap:12px}.colab-df-convert{background-color:#e8f0fe;border:0;border-radius:50%;cursor:pointer;display:none;fill:#1967d2;height:32px;padding:0;width:32px}.colab-df-convert:hover{background-color:#e2ebfa;box-shadow:0 1px 2px rgba(60,64,67,0.3),0px 1px 3px 1px rgba(60,64,67,0.15);fill:#174ea6}.colab-df-buttons div{margin-bottom:4px}[theme=dark] .colab-df-convert{background-color:#3b4455;fill:#d2e3fc}[theme=dark] .colab-df-convert:hover{background-color:#434b5c;box-shadow:0 1px 3px 1px rgba(0,0,0,0.15);filter:drop-shadow(0 1px 2px rgba(0,0,0,0.3));fill:#fff}</style> <script>
      const buttonEl =
        document.querySelector('#df-4097d005-8640-4a5e-84b9-ffad21cf2071 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-4097d005-8640-4a5e-84b9-ffad21cf2071');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script> </div> </div> </div> <p>Our test set has a smaller <em>count</em> of missing values than our training set (100 for <code class="language-plaintext highlighter-rouge">BMI</code>, <code class="language-plaintext highlighter-rouge">Weight</code>, and <code class="language-plaintext highlighter-rouge">Height</code> versus 196, respectively), but because our test set only contains 30% of the data from <code class="language-plaintext highlighter-rouge">final_df</code>, the proportion of missing values is much higher in comparison (24% versus 20%).</p> <p>Once we create the pipelines for our final models, we can include imputers to fill in these remaining missing values.</p> <h2 id="outliers">Outliers</h2> <p>Outliers, while potentially representing unusual or erroneous values, can also be informative about the real menstrual cycle lengths of American women. Removing them can skew our final model’s understanding of the underlying data distribution, leading to incorrect predictions on new data points that may include similar outliers.</p> <p>Let’s start by plotting our variables with boxplots to see whether outliers exist in each of them.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create figure and subplots
</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>  <span class="c1"># one row, three columns
</span>
<span class="c1"># list of cycles and subplot axes
</span><span class="n">cycles</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Cycle_1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cycle_2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cycle_3</span><span class="sh">'</span><span class="p">]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Cycle 1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cycle 2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Cycle 3</span><span class="sh">'</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">cycle</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">title</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">cycles</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">titles</span><span class="p">)):</span>
    <span class="c1"># calculate quartiles and IQR
</span>    <span class="n">Q1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">final_df</span><span class="p">[</span><span class="n">cycle</span><span class="p">],</span> <span class="mi">25</span><span class="p">)</span>
    <span class="n">Q3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">final_df</span><span class="p">[</span><span class="n">cycle</span><span class="p">],</span> <span class="mi">75</span><span class="p">)</span>
    <span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>

    <span class="c1"># calculate median
</span>    <span class="n">median</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="n">cycle</span><span class="p">].</span><span class="nf">median</span><span class="p">()</span>

    <span class="c1"># define outlier bounds
</span>    <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
    <span class="n">lower_bound</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>

    <span class="c1"># identify outliers
</span>    <span class="n">outliers</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="n">cycle</span><span class="p">][(</span><span class="n">final_df</span><span class="p">[</span><span class="n">cycle</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">lower_bound</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">final_df</span><span class="p">[</span><span class="n">cycle</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">upper_bound</span><span class="p">)]</span>

    <span class="c1"># create the boxplot
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">final_df</span><span class="p">[</span><span class="n">cycle</span><span class="p">],</span> <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s">: Boxplot with Labeled Median and Outliers</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_xticks</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_xticklabels</span><span class="p">([</span><span class="n">title</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Value</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># add median label
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">median</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">Median: </span><span class="si">{</span><span class="n">median</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">bottom</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># plot and label outliers
</span>    <span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)),</span> <span class="n">outliers</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Outliers</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">outlier</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">outliers</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="n">outlier</span><span class="p">,</span> <span class="nf">str</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">outlier</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># add legend only to first plot to avoid clutter
</span>    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>

<span class="c1"># adjust final layout
</span><span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><img src="ML_final_project_files/ML_final_project_106_0.png" alt="png"></p> <p>From these cycle boxplots, we can see that all three cycle variables have the same median, 28, which matches previous findings on average cycle lengths among the population.</p> <p>Additionally, we can see that all three variables have a relatively large number of outliers, with more outliers present in the farther range of values (outliers with longer cycle lengths than typical). Indeed, some women in the sample had cycles that were 54 days long, much longer than the average 28 days.</p> <p>This contradicts the study inclusion criteria, which required that participants have a stated menstrual cycle length ranging between 21-42 days long. However, it is unlikely that 54 days is an implausible or inaccurate measurement. A menstrual cycle length of 54 days, although concerning and atypical, is not impossible.</p> <p>The large number of outliers within our cycle variables may be some cause for concern, especially when it comes to building accurate models. However, let’s first look at our other predictor variables to see if outliers exist in them too.</p> <p>Let’s focus on just <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Height</code>, and <code class="language-plaintext highlighter-rouge">Weight</code> when looking for outliers, since <code class="language-plaintext highlighter-rouge">Height</code> and <code class="language-plaintext highlighter-rouge">Weight</code> capture all the information within <code class="language-plaintext highlighter-rouge">BMI</code>.</p> <p>Since these variables contain missing values, we will have to filter them first to remove the NAs before creating the boxplots.</p> <p>Let’s look at each of these variables individually.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Age
</span>
<span class="c1"># create filtered dataset that removes NAs
</span><span class="n">filtered_data</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="o">~</span><span class="n">final_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">()]</span>

<span class="c1"># calculate quartiles and IQR
</span><span class="n">Q1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">],</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">Q3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">],</span> <span class="mi">75</span><span class="p">)</span>
<span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>

<span class="c1"># calculate median
</span><span class="n">median</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">].</span><span class="nf">median</span><span class="p">()</span>

<span class="c1"># define outlier bounds
</span><span class="n">upper_bound</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>

<span class="c1"># identify outliers
</span><span class="n">outliers</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">][(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">lower_bound</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">upper_bound</span><span class="p">)]</span>

<span class="c1"># create the plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Age</span><span class="sh">"</span><span class="p">],</span> <span class="n">tick_labels</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">],</span> <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># ✅ Fixed this line
</span>
<span class="c1"># add median label slightly above the box
</span><span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">median</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">Median: </span><span class="si">{</span><span class="n">median</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">bottom</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># plot and label outliers
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)),</span> <span class="n">outliers</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Outliers</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">outlier</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">outliers</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="n">outlier</span><span class="p">,</span> <span class="nf">str</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">outlier</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># add labels and title
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Age: Boxplot with Labeled Median and Outliers</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><img src="ML_final_project_files/ML_final_project_109_0.png" alt="png"></p> <p>Our <code class="language-plaintext highlighter-rouge">Age</code> variable has a median age of 32 years old.</p> <p>From this boxplot, we can see that there are no outliers within <code class="language-plaintext highlighter-rouge">Age</code>!</p> <p>This is likely explained by the original study by Fehring et al. having inclusion criteria for participants that they must be between the ages of 18 and 42 years old. This leaves only 25 possible values that can exist for <code class="language-plaintext highlighter-rouge">Age</code>. Thus, there are no outliers present!</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Height
</span>
<span class="c1"># create filtered dataset that removes NAs
</span><span class="n">filtered_data</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="o">~</span><span class="n">final_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Height</span><span class="sh">'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">()]</span>

<span class="c1"># calculate quartiles and IQR
</span><span class="n">Q1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">],</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">Q3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">],</span> <span class="mi">75</span><span class="p">)</span>
<span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>

<span class="c1"># calculate median
</span><span class="n">median</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="p">[</span><span class="sh">'</span><span class="s">Height</span><span class="sh">'</span><span class="p">].</span><span class="nf">median</span><span class="p">()</span>

<span class="c1"># define outlier bounds
</span><span class="n">upper_bound</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>

<span class="c1"># identify outliers
</span><span class="n">outliers</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">][(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">lower_bound</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">upper_bound</span><span class="p">)]</span>

<span class="c1"># create the plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Height</span><span class="sh">"</span><span class="p">],</span> <span class="n">tick_labels</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Height</span><span class="sh">'</span><span class="p">],</span> <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># ✅ Fixed this line
</span>
<span class="c1"># add median label slightly above the box
</span><span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">median</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">Median: </span><span class="si">{</span><span class="n">median</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">bottom</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># plot and label outliers
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)),</span> <span class="n">outliers</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Outliers</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">outlier</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">outliers</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="n">outlier</span><span class="p">,</span> <span class="nf">str</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">outlier</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># add labels and title
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Height: Boxplot with Labeled Median and Outliers</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Height</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><img src="ML_final_project_files/ML_final_project_111_0.png" alt="png"></p> <p>The median height of participants within our dataset is 65 inches, which is about 5 feet, 4 inches. This matches the population, with the average American women’s height being 5 feet, 4 inches.</p> <p>Similar to <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Height</code> has no outliers present. The upper and lower whiskers contain minimum and maximum heights that fall within normal ranges found in the population as well (about 5 feet at the lowest and 6 feet at the highest).</p> <p>Source: <a href="https://www.cdc.gov/nchs/fastats/body-measurements.htm" rel="external nofollow noopener" target="_blank">CDC: Body Measurements</a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Weight
</span>
<span class="c1"># create filtered dataset that removes NAs
</span><span class="n">filtered_data</span> <span class="o">=</span> <span class="n">final_df</span><span class="p">[</span><span class="o">~</span><span class="n">final_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Weight</span><span class="sh">'</span><span class="p">].</span><span class="nf">isnull</span><span class="p">()]</span>

<span class="c1"># calculate quartiles and IQR
</span><span class="n">Q1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">],</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">Q3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">],</span> <span class="mi">75</span><span class="p">)</span>
<span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>

<span class="c1"># calculate median
</span><span class="n">median</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="p">[</span><span class="sh">'</span><span class="s">Weight</span><span class="sh">'</span><span class="p">].</span><span class="nf">median</span><span class="p">()</span>

<span class="c1"># define outlier bounds
</span><span class="n">upper_bound</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>

<span class="c1"># identify outliers
</span><span class="n">outliers</span> <span class="o">=</span> <span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">][(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">lower_bound</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">upper_bound</span><span class="p">)]</span>

<span class="c1"># create the plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">filtered_data</span><span class="p">[</span><span class="sh">"</span><span class="s">Weight</span><span class="sh">"</span><span class="p">],</span> <span class="n">tick_labels</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Weight</span><span class="sh">'</span><span class="p">],</span> <span class="n">showfliers</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># ✅ Fixed this line
</span>
<span class="c1"># add median label slightly above the box
</span><span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">median</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">f</span><span class="sh">'</span><span class="s">Median: </span><span class="si">{</span><span class="n">median</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">bottom</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># plot and label outliers
</span><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">outliers</span><span class="p">)),</span> <span class="n">outliers</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Outliers</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">outlier</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">outliers</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="n">outlier</span><span class="p">,</span> <span class="nf">str</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">outlier</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">va</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># add labels and title
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Weight: Boxplot with Labeled Median and Outliers</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Weight</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><img src="ML_final_project_files/ML_final_project_113_0.png" alt="png"></p> <p>The median weight of our sample is 145 pounds.</p> <p>There are three outlier values present in <code class="language-plaintext highlighter-rouge">Weight</code>: 260 pounds, 268 pounds, and 300 pounds.</p> <p>Given that bodies come in a wide range of sizes (and therefore weights), and that there are only three outliers present in <code class="language-plaintext highlighter-rouge">Weight</code>, I do not believe these outliers are cause for concern and do not need to be “dealt with” in any way.</p> <p>Overall, from these boxplots we can see that the only columns with outliers that are truly cause for concern when creating our models are <code class="language-plaintext highlighter-rouge">Cycle_1</code>, <code class="language-plaintext highlighter-rouge">Cycle_2</code>, and <code class="language-plaintext highlighter-rouge">Cycle_3</code>.</p> <p>However, the final model that we end up selecting for the predictor tool has an impact on whether we need to transform these outliers.</p> <p>If our final model is a linear regression model, these types of models are very sensitive to outliers, since these models try to minimize the sum of squared errors (SSE). The SSE is a measure of how well the model fits with the data. Outliers, being data poins far from the general trend, can disproportionally impact the SSE calculations, resulting in a skewed regression line. This skewed line can result in a poor fit for the rest of the data, reducing prediction accuracy.</p> <p>If model fitting and tuning determines that a linear regression model is the best fit model for our predictor tool, we will have to determine a strategy to transform the outliers to reduce this skewed result.</p> <p>Similarly, if a KNN model is found to have the best predictive power, we will have to edit these outliers. KNN models can be sensitive to outliers, especially when the value of k (number of neighbours) is small. When k is small, the influence of a single outlier is magnified. Outliers can disproportionately influence the prediction because KNN relies on the distances to the nearest neighbours to make a classification.</p> <p>However, if the final model ends up being a tree-based model such as xgboost, we will not need to worry about removing these outliers. Tree-based models are generally robust to outliers as they focus mainly on dividing data based on splits instead of relying on absolute values or distances. Outliers are thus often “quarantined” within their own nodes, which limits their influence on the entire model.</p> <p>So, with all this in mind, let’s determine which model is optimal and then decide whether we need to remove outliers from our data or not.</p> <h1 id="pipeline">Pipeline</h1> <p>We will need to create a pipeline in order to impute missing values into our dataset.</p> <h3 id="bmi">BMI</h3> <p>First, however, I want to make sure that the missing values within our <code class="language-plaintext highlighter-rouge">BMI</code> column are not imputed using the imputer. Its values can only be accurately determined from the values within <code class="language-plaintext highlighter-rouge">Height</code> and <code class="language-plaintext highlighter-rouge">Weight</code>, not just the mean or median BMI for the entire sample.</p> <p>So, let’s write some code that will calculate the BMI for each Client to ensure that any missing BMI values will be filled.</p> <p>Since the values of the “Height” and “Weight” columns are in the US customary units (pounds (lbs) and inches), we can calculate BMI for each row using the following formula:</p> <p><strong>US customary units: BMI = weight (pounds) / [height (in)]^2 x 703</strong></p> <p>Source: <a href="https://www.cdc.gov/growth-chart-training/hcp/using-bmi/body-mass-index.html" rel="external nofollow noopener" target="_blank">CDC, What Is Body Mass Index (BMI)?</a></p> <p>Written in code, that formula looks like this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BMICalculator</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># BMI, Weight, and Height are at indices 5, 4, and 3 respectively
</span>        <span class="c1"># Calculate BMI for rows where it's missing but Weight and Height are available
</span>        <span class="n">missing_bmi_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">5</span><span class="p">])</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">])</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="n">X</span><span class="p">[</span><span class="n">missing_bmi_mask</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">missing_bmi_mask</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="o">/</span> <span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="n">missing_bmi_mask</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Calculate BMI using NumPy array operations
</span>        <span class="c1"># Convert kg and cm to m^2 by /100^2
</span>
        <span class="k">return</span> <span class="n">X</span>
</code></pre></div></div> <p>Before building our models, let’s first create a K-fold object to set up our cross-validation.</p> <p>Creating a kf object allows us to:</p> <ul> <li>specify a random_state so that results are always the same</li> <li>shuffle = True shuffles the dataset <ul> <li>If there is something non-random about the order of the rows, then not shuffling with affect results</li> </ul> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set up cross-validation
</span><span class="n">kf</span> <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div> <h1 id="model-fitting">Model fitting</h1> <p>We will determine which model is the most optimal by calculating the difference between the actual target values in the testing set and the values predicted by the model with Root Mean Square Error (RMSE).</p> <p>The RMSE determines the absolute fit of the model to the data and indicates how close the actual data points are to the model’s predicted values.</p> <p>Notably, we will not be making any predictions on the length of <code class="language-plaintext highlighter-rouge">Cycle_3</code> that we dont’ already have data on. Instead, we will have each of our models predict the lengths of Cycle 3 of each Client in the test set based on the lengths of Cycles 1 and 2 and we will then <em>compare</em> those predicted lengths to the <em>actual</em> Cycle 3 lengths in our dataset.</p> <p>RMSE is the most appropriate metric to use to compare these models, as it is considered a standard metric in regression problems and is measured in the same units as the dependent variable, <code class="language-plaintext highlighter-rouge">Cycle_3</code> (days), making it directly interpretable.</p> <p>A <em>low</em> RMSE value indicates a better fitting model and is a good measure for determining the accuracy of the model’s predictions.</p> <h2 id="linear-regression">Linear regression</h2> <p>We should first create a simple linear regression model that will serve as our <em>comparison model</em> for all the other more complex models we will build. This is because a linear regression model is one of the simplest models with which to build a machine learning model from.</p> <p>The only parameter we will tune is the imputer strategy, just to see which we should potentially use for the rest of our models.</p> <p>By doing so, we can answer the question: “Does this model perform better than a simple linear regression model?”</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># simple linear regression
</span><span class="n">linear_pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">imputer</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">bmi_calc</span><span class="sh">'</span><span class="p">,</span> <span class="nc">BMICalculator</span><span class="p">()),</span> <span class="c1"># after SimpleImputer and before StandardScaler
</span>    <span class="p">(</span><span class="sh">'</span><span class="s">scaler</span><span class="sh">'</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">,</span> <span class="nc">LinearRegression</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Define the parameter grid for GridSearchCV
</span><span class="n">linear_param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">imputer__strategy</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">median</span><span class="sh">'</span><span class="p">],</span> <span class="c1"># explore different imputation strategies
</span><span class="p">}</span>

<span class="n">linear_cv</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span>
    <span class="n">linear_pipeline</span><span class="p">,</span>
    <span class="n">linear_param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">neg_root_mean_squared_error</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span>  <span class="c1"># also track training scores
</span><span class="p">)</span>

<span class="n">linear_cv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div> <style>#sk-container-id-1{--sklearn-color-text:#000;--sklearn-color-text-muted:#666;--sklearn-color-line:gray;--sklearn-color-unfitted-level-0:#fff5e6;--sklearn-color-unfitted-level-1:#f6e4d2;--sklearn-color-unfitted-level-2:#ffe0b3;--sklearn-color-unfitted-level-3:chocolate;--sklearn-color-fitted-level-0:#f0f8ff;--sklearn-color-fitted-level-1:#d4ebff;--sklearn-color-fitted-level-2:#b3dbfd;--sklearn-color-fitted-level-3:cornflowerblue;--sklearn-color-text-on-default-background:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,black)));--sklearn-color-background:var(--sg-background-color,var(--theme-background,var(--jp-layout-color0,white)));--sklearn-color-border-box:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,black)));--sklearn-color-icon:#696969;@media(prefers-color-scheme:dark){--sklearn-color-text-on-default-background:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,white)));--sklearn-color-background:var(--sg-background-color,var(--theme-background,var(--jp-layout-color0,#111)));--sklearn-color-border-box:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,white)));--sklearn-color-icon:#878787}}#sk-container-id-1{color:var(--sklearn-color-text)}#sk-container-id-1 pre{padding:0}#sk-container-id-1 input.sk-hidden--visually{border:0;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#sk-container-id-1 div.sk-dashed-wrapped{border:1px dashed var(--sklearn-color-line);margin:0 .4em .5em .4em;box-sizing:border-box;padding-bottom:.4em;background-color:var(--sklearn-color-background)}#sk-container-id-1 div.sk-container{display:inline-block!important;position:relative}#sk-container-id-1 div.sk-text-repr-fallback{display:none}div.sk-parallel-item,div.sk-serial,div.sk-item{background-image:linear-gradient(var(--sklearn-color-text-on-default-background),var(--sklearn-color-text-on-default-background));background-size:2px 100%;background-repeat:no-repeat;background-position:center center}#sk-container-id-1 div.sk-parallel-item::after{content:"";width:100%;border-bottom:2px solid var(--sklearn-color-text-on-default-background);flex-grow:1}#sk-container-id-1 div.sk-parallel{display:flex;align-items:stretch;justify-content:center;background-color:var(--sklearn-color-background);position:relative}#sk-container-id-1 div.sk-parallel-item{display:flex;flex-direction:column}#sk-container-id-1 div.sk-parallel-item:first-child::after{align-self:flex-end;width:50%}#sk-container-id-1 div.sk-parallel-item:last-child::after{align-self:flex-start;width:50%}#sk-container-id-1 div.sk-parallel-item:only-child::after{width:0}#sk-container-id-1 div.sk-serial{display:flex;flex-direction:column;align-items:center;background-color:var(--sklearn-color-background);padding-right:1em;padding-left:1em}#sk-container-id-1 div.sk-toggleable{background-color:var(--sklearn-color-background)}#sk-container-id-1 label.sk-toggleable__label{cursor:pointer;display:flex;width:100%;margin-bottom:0;padding:.5em;box-sizing:border-box;text-align:center;align-items:start;justify-content:space-between;gap:.5em}#sk-container-id-1 label.sk-toggleable__label .caption{font-size:.6rem;font-weight:lighter;color:var(--sklearn-color-text-muted)}#sk-container-id-1 label.sk-toggleable__label-arrow:before{content:"▸";float:left;margin-right:.25em;color:var(--sklearn-color-icon)}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before{color:var(--sklearn-color-text)}#sk-container-id-1 div.sk-toggleable__content{max-height:0;max-width:0;overflow:hidden;text-align:left;background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-1 div.sk-toggleable__content.fitted{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-1 div.sk-toggleable__content pre{margin:.2em;border-radius:.25em;color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-1 div.sk-toggleable__content.fitted pre{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content{max-height:200px;max-width:100%;overflow:auto}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before{content:"▾"}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label{color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-fitted-level-2)}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-fitted-level-2)}
#sk-container-id-1 div.sk-label label.sk-toggleable__label,#sk-container-id-1 div.sk-label label{color:var(--sklearn-color-text-on-default-background)}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label{color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted{color:var(--sklearn-color-text);background-color:var(--sklearn-color-fitted-level-2)}#sk-container-id-1 div.sk-label label{font-family:monospace;font-weight:bold;display:inline-block;line-height:1.2em}#sk-container-id-1 div.sk-label-container{text-align:center}#sk-container-id-1 div.sk-estimator{font-family:monospace;border:1px dotted var(--sklearn-color-border-box);border-radius:.25em;box-sizing:border-box;margin-bottom:.5em;background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-1 div.sk-estimator.fitted{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-1 div.sk-estimator:hover{background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-1 div.sk-estimator.fitted:hover{background-color:var(--sklearn-color-fitted-level-2)}.sk-estimator-doc-link,a:link.sk-estimator-doc-link,a:visited.sk-estimator-doc-link{float:right;font-size:smaller;line-height:1em;font-family:monospace;background-color:var(--sklearn-color-background);border-radius:1em;height:1em;width:1em;text-decoration:none!important;margin-left:.5em;text-align:center;border:var(--sklearn-color-unfitted-level-1) 1pt solid;color:var(--sklearn-color-unfitted-level-1)}.sk-estimator-doc-link.fitted,a:link.sk-estimator-doc-link.fitted,a:visited.sk-estimator-doc-link.fitted{border:var(--sklearn-color-fitted-level-1) 1pt solid;color:var(--sklearn-color-fitted-level-1)}div.sk-estimator:hover .sk-estimator-doc-link:hover,.sk-estimator-doc-link:hover,div.sk-label-container:hover .sk-estimator-doc-link:hover,.sk-estimator-doc-link:hover{background-color:var(--sklearn-color-unfitted-level-3);color:var(--sklearn-color-background);text-decoration:none}div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,.sk-estimator-doc-link.fitted:hover,div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,.sk-estimator-doc-link.fitted:hover{background-color:var(--sklearn-color-fitted-level-3);color:var(--sklearn-color-background);text-decoration:none}.sk-estimator-doc-link span{display:none;z-index:9999;position:relative;font-weight:normal;right:.2ex;padding:.5ex;margin:.5ex;width:min-content;min-width:20ex;max-width:50ex;color:var(--sklearn-color-text);box-shadow:2pt 2pt 4pt #999;background:var(--sklearn-color-unfitted-level-0);border:.5pt solid var(--sklearn-color-unfitted-level-3)}.sk-estimator-doc-link.fitted span{background:var(--sklearn-color-fitted-level-0);border:var(--sklearn-color-fitted-level-3)}.sk-estimator-doc-link:hover span{display:block}#sk-container-id-1 a.estimator_doc_link{float:right;font-size:1rem;line-height:1em;font-family:monospace;background-color:var(--sklearn-color-background);border-radius:1rem;height:1rem;width:1rem;text-decoration:none;color:var(--sklearn-color-unfitted-level-1);border:var(--sklearn-color-unfitted-level-1) 1pt solid}#sk-container-id-1 a.estimator_doc_link.fitted{border:var(--sklearn-color-fitted-level-1) 1pt solid;color:var(--sklearn-color-fitted-level-1)}#sk-container-id-1 a.estimator_doc_link:hover{background-color:var(--sklearn-color-unfitted-level-3);color:var(--sklearn-color-background);text-decoration:none}#sk-container-id-1 a.estimator_doc_link.fitted:hover{background-color:var(--sklearn-color-fitted-level-3)}</style> <div id="sk-container-id-1" class="sk-top-container"> <div class="sk-text-repr-fallback"> <pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('imputer', SimpleImputer()),
                                       ('bmi_calc', BMICalculator()),
                                       ('scaler', StandardScaler()),
                                       ('linear', LinearRegression())]),
             param_grid={'imputer__strategy': ['mean', 'median']},
             return_train_score=True, scoring='neg_root_mean_squared_error')</pre> <b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b> </div> <div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"> <div class="sk-label-container"><div class="sk-label fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>GridSearchCV</div></div> <div> <a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span> </div></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('imputer', SimpleImputer()),
                                       ('bmi_calc', BMICalculator()),
                                       ('scaler', StandardScaler()),
                                       ('linear', LinearRegression())]),
             param_grid={'imputer__strategy': ['mean', 'median']},
             return_train_score=True, scoring='neg_root_mean_squared_error')</pre></div> </div></div> <div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"> <div class="sk-label-container"><div class="sk-label fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>best_estimator_: Pipeline</div></div></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('imputer', SimpleImputer()), ('bmi_calc', BMICalculator()),
                ('scaler', StandardScaler()), ('linear', LinearRegression())])</pre></div> </div></div> <div class="sk-serial"><div class="sk-item"><div class="sk-serial"> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>SimpleImputer</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html">?<span>Documentation for SimpleImputer</span></a></div></label><div class="sk-toggleable__content fitted"><pre>SimpleImputer()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>BMICalculator</div></div></label><div class="sk-toggleable__content fitted"><pre>BMICalculator()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox"><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>StandardScaler</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></div></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>LinearRegression</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html">?<span>Documentation for LinearRegression</span></a></div></label><div class="sk-toggleable__content fitted"><pre>LinearRegression()</pre></div> </div></div> </div></div></div> </div></div></div> </div></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">best_linear_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">linear_cv</span><span class="p">.</span><span class="n">best_score_</span>  <span class="c1"># convert back to MSE
</span><span class="n">linear_model</span> <span class="o">=</span> <span class="n">linear_cv</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="c1"># print optimization results
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Linear regression: </span><span class="se">\n</span><span class="s"> Best parameters:</span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="n">linear_cv</span><span class="p">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s"> </span><span class="se">\n\n</span><span class="s"> RMSE: **</span><span class="si">{</span><span class="n">best_linear_score</span><span class="si">}</span><span class="s">**</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Linear regression: 
 Best parameters:
 {'imputer__strategy': 'mean'} 

 RMSE: **3.2793947453484256**
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">From our 5-fold cross-validation, the simple linear regression model</span><span class="sh">'</span><span class="s">s predictions for Cycle_3 were on average </span><span class="si">{</span><span class="n">best_linear_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> days off from the actual lengths.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>From our 5-fold cross-validation, the simple linear regression model's predictions for Cycle_3 were on average 3.28 days off from the actual lengths.
</code></pre></div></div> <p>From our hyperparameter tuning of the imputer strategy, it looks like <strong>mean</strong> is the best imputer strategy. Since it was deemed the most optimal strategy for our simple linear regression model, let’s go ahead and use a mean imputer for our subsequent models.</p> <p>Let’s move onto a slightly more advanced algorithm: ElasticNet Regression.</p> <h2 id="elasticnet-regression">ElasticNet regression</h2> <p>ElasticNet Regression is a powerful machine learning algorithm that combines the features of Lasso (L1) and Ridge (L2) Regression by determining the degree and strength with which to apply <strong>both an L1 and L2 penalty at the same time</strong>.</p> <p>It is an improvement to a simple linear regression model in that it addresses the issues that simple linear regression has with multicollinearity. When predictor variables are highly correlated with one another (ie., multicollinearity), this can lead to unstable and inaccurate coefficient estimates. Additionally, a simple linear regression model does not perform feature selection and includes all predictors in the model, potentially leading to an overcomplicated model.</p> <p>ElasticNet, on the other hand, combines the strengths of Lasso and Ridge, allowing it to address multicollinearity more effectively. By instituing an L1 penalty term, it can also force coefficients of less important predictors to zero.</p> <p>Let’s determine which hyperparameters we should tune for our ElasticNet model.</p> <p><strong>Hyperparameters to tune</strong></p> <p><code class="language-plaintext highlighter-rouge">alpha</code> = strength of the regularization</p> <ul> <li>must be a positive float, value between 0 and 1 <ul> <li>0 = all weight to the L2 penalty</li> <li>1 = all weight to the L1 penalty</li> </ul> </li> <li>1 minus the alpha value = the strength of the L2 penalty</li> <li>For example, an alpha of 0.5 would provide a 50 percent contribution of each penalty to the loss function. An alpha value of 0 gives all weight to the L2 penalty and a value of 1 gives all weight to the L1 penalty.</li> </ul> <p><code class="language-plaintext highlighter-rouge">l1_ratio</code> = determines the mix between L1 and L2 regularization</p> <ul> <li>= 1: entirely lasso penalty (L1)</li> <li>= 0: entirely ridge penalty (L2)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># print best params correclty (not as float()
</span><span class="n">np</span><span class="p">.</span><span class="nf">set_printoptions</span><span class="p">(</span><span class="n">legacy</span><span class="o">=</span><span class="sh">'</span><span class="s">1.25</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># ElasticNet Regression with GridSearchCV
</span><span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">l1_ratios</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>

<span class="n">elasticnet_pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">imputer</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">bmi_calc</span><span class="sh">'</span><span class="p">,</span> <span class="nc">BMICalculator</span><span class="p">()),</span> <span class="c1"># after SimpleImputer and before StandardScaler
</span>    <span class="p">(</span><span class="sh">'</span><span class="s">scaler</span><span class="sh">'</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">elasticnet</span><span class="sh">'</span><span class="p">,</span> <span class="nc">ElasticNet</span><span class="p">())</span>
<span class="p">])</span>

<span class="n">elasticnet_params</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">elasticnet__alpha</span><span class="sh">'</span><span class="p">:</span> <span class="n">alphas</span><span class="p">,</span>
                    <span class="sh">'</span><span class="s">elasticnet__l1_ratio</span><span class="sh">'</span><span class="p">:</span> <span class="n">l1_ratios</span><span class="p">}</span>

<span class="n">elasticnet_cv</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span>
    <span class="n">elasticnet_pipeline</span><span class="p">,</span>
    <span class="n">elasticnet_params</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">neg_root_mean_squared_error</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span>  <span class="c1"># also track training scores
</span><span class="p">)</span>
<span class="n">elasticnet_cv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div> <style>#sk-container-id-2{--sklearn-color-text:#000;--sklearn-color-text-muted:#666;--sklearn-color-line:gray;--sklearn-color-unfitted-level-0:#fff5e6;--sklearn-color-unfitted-level-1:#f6e4d2;--sklearn-color-unfitted-level-2:#ffe0b3;--sklearn-color-unfitted-level-3:chocolate;--sklearn-color-fitted-level-0:#f0f8ff;--sklearn-color-fitted-level-1:#d4ebff;--sklearn-color-fitted-level-2:#b3dbfd;--sklearn-color-fitted-level-3:cornflowerblue;--sklearn-color-text-on-default-background:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,black)));--sklearn-color-background:var(--sg-background-color,var(--theme-background,var(--jp-layout-color0,white)));--sklearn-color-border-box:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,black)));--sklearn-color-icon:#696969;@media(prefers-color-scheme:dark){--sklearn-color-text-on-default-background:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,white)));--sklearn-color-background:var(--sg-background-color,var(--theme-background,var(--jp-layout-color0,#111)));--sklearn-color-border-box:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,white)));--sklearn-color-icon:#878787}}#sk-container-id-2{color:var(--sklearn-color-text)}#sk-container-id-2 pre{padding:0}#sk-container-id-2 input.sk-hidden--visually{border:0;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#sk-container-id-2 div.sk-dashed-wrapped{border:1px dashed var(--sklearn-color-line);margin:0 .4em .5em .4em;box-sizing:border-box;padding-bottom:.4em;background-color:var(--sklearn-color-background)}#sk-container-id-2 div.sk-container{display:inline-block!important;position:relative}#sk-container-id-2 div.sk-text-repr-fallback{display:none}div.sk-parallel-item,div.sk-serial,div.sk-item{background-image:linear-gradient(var(--sklearn-color-text-on-default-background),var(--sklearn-color-text-on-default-background));background-size:2px 100%;background-repeat:no-repeat;background-position:center center}#sk-container-id-2 div.sk-parallel-item::after{content:"";width:100%;border-bottom:2px solid var(--sklearn-color-text-on-default-background);flex-grow:1}#sk-container-id-2 div.sk-parallel{display:flex;align-items:stretch;justify-content:center;background-color:var(--sklearn-color-background);position:relative}#sk-container-id-2 div.sk-parallel-item{display:flex;flex-direction:column}#sk-container-id-2 div.sk-parallel-item:first-child::after{align-self:flex-end;width:50%}#sk-container-id-2 div.sk-parallel-item:last-child::after{align-self:flex-start;width:50%}#sk-container-id-2 div.sk-parallel-item:only-child::after{width:0}#sk-container-id-2 div.sk-serial{display:flex;flex-direction:column;align-items:center;background-color:var(--sklearn-color-background);padding-right:1em;padding-left:1em}#sk-container-id-2 div.sk-toggleable{background-color:var(--sklearn-color-background)}#sk-container-id-2 label.sk-toggleable__label{cursor:pointer;display:flex;width:100%;margin-bottom:0;padding:.5em;box-sizing:border-box;text-align:center;align-items:start;justify-content:space-between;gap:.5em}#sk-container-id-2 label.sk-toggleable__label .caption{font-size:.6rem;font-weight:lighter;color:var(--sklearn-color-text-muted)}#sk-container-id-2 label.sk-toggleable__label-arrow:before{content:"▸";float:left;margin-right:.25em;color:var(--sklearn-color-icon)}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before{color:var(--sklearn-color-text)}#sk-container-id-2 div.sk-toggleable__content{max-height:0;max-width:0;overflow:hidden;text-align:left;background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-2 div.sk-toggleable__content.fitted{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-2 div.sk-toggleable__content pre{margin:.2em;border-radius:.25em;color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-2 div.sk-toggleable__content.fitted pre{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content{max-height:200px;max-width:100%;overflow:auto}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before{content:"▾"}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label{color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-fitted-level-2)}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-fitted-level-2)}
#sk-container-id-2 div.sk-label label.sk-toggleable__label,#sk-container-id-2 div.sk-label label{color:var(--sklearn-color-text-on-default-background)}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label{color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted{color:var(--sklearn-color-text);background-color:var(--sklearn-color-fitted-level-2)}#sk-container-id-2 div.sk-label label{font-family:monospace;font-weight:bold;display:inline-block;line-height:1.2em}#sk-container-id-2 div.sk-label-container{text-align:center}#sk-container-id-2 div.sk-estimator{font-family:monospace;border:1px dotted var(--sklearn-color-border-box);border-radius:.25em;box-sizing:border-box;margin-bottom:.5em;background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-2 div.sk-estimator.fitted{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-2 div.sk-estimator:hover{background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-2 div.sk-estimator.fitted:hover{background-color:var(--sklearn-color-fitted-level-2)}.sk-estimator-doc-link,a:link.sk-estimator-doc-link,a:visited.sk-estimator-doc-link{float:right;font-size:smaller;line-height:1em;font-family:monospace;background-color:var(--sklearn-color-background);border-radius:1em;height:1em;width:1em;text-decoration:none!important;margin-left:.5em;text-align:center;border:var(--sklearn-color-unfitted-level-1) 1pt solid;color:var(--sklearn-color-unfitted-level-1)}.sk-estimator-doc-link.fitted,a:link.sk-estimator-doc-link.fitted,a:visited.sk-estimator-doc-link.fitted{border:var(--sklearn-color-fitted-level-1) 1pt solid;color:var(--sklearn-color-fitted-level-1)}div.sk-estimator:hover .sk-estimator-doc-link:hover,.sk-estimator-doc-link:hover,div.sk-label-container:hover .sk-estimator-doc-link:hover,.sk-estimator-doc-link:hover{background-color:var(--sklearn-color-unfitted-level-3);color:var(--sklearn-color-background);text-decoration:none}div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,.sk-estimator-doc-link.fitted:hover,div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,.sk-estimator-doc-link.fitted:hover{background-color:var(--sklearn-color-fitted-level-3);color:var(--sklearn-color-background);text-decoration:none}.sk-estimator-doc-link span{display:none;z-index:9999;position:relative;font-weight:normal;right:.2ex;padding:.5ex;margin:.5ex;width:min-content;min-width:20ex;max-width:50ex;color:var(--sklearn-color-text);box-shadow:2pt 2pt 4pt #999;background:var(--sklearn-color-unfitted-level-0);border:.5pt solid var(--sklearn-color-unfitted-level-3)}.sk-estimator-doc-link.fitted span{background:var(--sklearn-color-fitted-level-0);border:var(--sklearn-color-fitted-level-3)}.sk-estimator-doc-link:hover span{display:block}#sk-container-id-2 a.estimator_doc_link{float:right;font-size:1rem;line-height:1em;font-family:monospace;background-color:var(--sklearn-color-background);border-radius:1rem;height:1rem;width:1rem;text-decoration:none;color:var(--sklearn-color-unfitted-level-1);border:var(--sklearn-color-unfitted-level-1) 1pt solid}#sk-container-id-2 a.estimator_doc_link.fitted{border:var(--sklearn-color-fitted-level-1) 1pt solid;color:var(--sklearn-color-fitted-level-1)}#sk-container-id-2 a.estimator_doc_link:hover{background-color:var(--sklearn-color-unfitted-level-3);color:var(--sklearn-color-background);text-decoration:none}#sk-container-id-2 a.estimator_doc_link.fitted:hover{background-color:var(--sklearn-color-fitted-level-3)}</style> <div id="sk-container-id-2" class="sk-top-container"> <div class="sk-text-repr-fallback"> <pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('imputer', SimpleImputer()),
                                       ('bmi_calc', BMICalculator()),
                                       ('scaler', StandardScaler()),
                                       ('elasticnet', ElasticNet())]),
             param_grid={'elasticnet__alpha': array([1.00000000e-02, 2.51188643e-02, 6.30957344e-02, 1.58489319e-01,
       3.98107171e-01, 1.00000000e+00, 2.51188643e+00, 6.30957344e+00,
       1.58489319e+01, 3.98107171e+01, 1.00000000e+02]),
                         'elasticnet__l1_ratio': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},
             return_train_score=True, scoring='neg_root_mean_squared_error')</pre> <b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b> </div> <div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"> <div class="sk-label-container"><div class="sk-label fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox"><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>GridSearchCV</div></div> <div> <a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span> </div></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('imputer', SimpleImputer()),
                                       ('bmi_calc', BMICalculator()),
                                       ('scaler', StandardScaler()),
                                       ('elasticnet', ElasticNet())]),
             param_grid={'elasticnet__alpha': array([1.00000000e-02, 2.51188643e-02, 6.30957344e-02, 1.58489319e-01,
       3.98107171e-01, 1.00000000e+00, 2.51188643e+00, 6.30957344e+00,
       1.58489319e+01, 3.98107171e+01, 1.00000000e+02]),
                         'elasticnet__l1_ratio': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])},
             return_train_score=True, scoring='neg_root_mean_squared_error')</pre></div> </div></div> <div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"> <div class="sk-label-container"><div class="sk-label fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox"><label for="sk-estimator-id-8" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>best_estimator_: Pipeline</div></div></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('imputer', SimpleImputer()), ('bmi_calc', BMICalculator()),
                ('scaler', StandardScaler()),
                ('elasticnet',
                 ElasticNet(alpha=0.06309573444801933, l1_ratio=1.0))])</pre></div> </div></div> <div class="sk-serial"><div class="sk-item"><div class="sk-serial"> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox"><label for="sk-estimator-id-9" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>SimpleImputer</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html">?<span>Documentation for SimpleImputer</span></a></div></label><div class="sk-toggleable__content fitted"><pre>SimpleImputer()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox"><label for="sk-estimator-id-10" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>BMICalculator</div></div></label><div class="sk-toggleable__content fitted"><pre>BMICalculator()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox"><label for="sk-estimator-id-11" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>StandardScaler</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></div></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-12" type="checkbox"><label for="sk-estimator-id-12" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>ElasticNet</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.ElasticNet.html">?<span>Documentation for ElasticNet</span></a></div></label><div class="sk-toggleable__content fitted"><pre>ElasticNet(alpha=0.06309573444801933, l1_ratio=1.0)</pre></div> </div></div> </div></div></div> </div></div></div> </div></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">best_elasticnet_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">elasticnet_cv</span><span class="p">.</span><span class="n">best_score_</span>  <span class="c1"># convert back to MSE
</span><span class="n">elasticnet_model</span> <span class="o">=</span> <span class="n">elasticnet_cv</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="c1"># print optimization results
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">ElasticNet: </span><span class="se">\n</span><span class="s"> Best parameters:</span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="n">elasticnet_cv</span><span class="p">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s"> </span><span class="se">\n\n</span><span class="s"> RMSE: **</span><span class="si">{</span><span class="n">best_elasticnet_score</span><span class="si">}</span><span class="s">**</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ElasticNet: 
 Best parameters:
 {'elasticnet__alpha': 0.06309573444801933, 'elasticnet__l1_ratio': 1.0} 

 RMSE: **3.2781404657526734**
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">From our 5-fold cross-validation, the ElasticNet model</span><span class="sh">'</span><span class="s">s predictions for Cycle_3 were on average </span><span class="si">{</span><span class="n">best_elasticnet_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> days off from the actual lengths.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>From our 5-fold cross-validation, the ElasticNet model's predictions for Cycle_3 were on average 3.28 days off from the actual lengths.
</code></pre></div></div> <p>Based on our hyperparameter tuning results, we can see that:</p> <p>An <strong>alpha value</strong> of 0.01 indicates that the model will primarily be influenced by the L2 penalty, as it is very close to 0 (with 0 meaning all weight is given to the L2 penalty). L2 (Ridge) regularization favours the shrinkage of coefficients without forcing them to zero.</p> <p>An <strong>l1_ratio</strong> value of 0 indicates that the mix of penalties resulted in an entirely ridge penalty. Ridge regressions create <em>stable</em> models by minimizing the impact of less important features while keeping all variables in the model. This prevents the model from overfitting, especially when there is not enough data, which is the case for our data.</p> <p>Overall, our ElasticNet regression model is behaving more like a Ridge regression.</p> <p>This suggests that overfitting may be a concern for our data. <strong>Overfitting</strong> occurs when a model learns the training data too well, including noise and irrelevant details, resulting in poor performance on new, unseen data.</p> <p>When a model yields a small training RMSE but a very large test RMSE, we are said to be overfitting the data. The testing set RMSE will be very large because the supposed patterns that the model found in the training set does not exist in the testing set.</p> <p>We should keep this in mind when evaluating our models’ training and test performance in the future.</p> <h2 id="xgb">XGB</h2> <p>With the knowledge that our data may be prone to overfitting, implementing an XGBoost model may be more appropriate as they are robust to noisy data, outliers, and missing values.</p> <p>XGBoost is a type of ensemble learning method that combines multiple weak models to form a stronger model.</p> <p>It uses decision trees as its “base learners”, combining them sequentially to improve the model’s performance. Each new tree “learns” (ie., is trained) from the previous tree to correct its errors; this process is called <strong>boosting</strong>.</p> <p>Like all machine learning algorithms, XGBoost supports customizations to allow users to adjust model hyperparameters to optimize performance based on the specific problem.</p> <p>So, let’s go ahead and review which hyperparameters we will be tuning for our own XGBoost model.</p> <p><strong>Hyperparameters to tune</strong></p> <p><code class="language-plaintext highlighter-rouge">n_estimators</code> = the number of boosting stages to perform, ie. how many trees will be in the model</p> <ul> <li>large number usually results in better performance but can lead to overfitting</li> </ul> <p><code class="language-plaintext highlighter-rouge">learning_rate</code> = aka “shrinkage”, governs how “greedy” each tree is. Is used to control and adjust the weighting of the internal model estimators.</p> <ul> <li>should always be a small value to force long-term learning.</li> <li>if you have a slow learning rate, it will take more time to converge, but it will resist overfitting more, as each tree will learn and improve only by a little bit each time</li> </ul> <p><code class="language-plaintext highlighter-rouge">max_depth</code> = the maximum depth of each tree</p> <ul> <li>increasing this = model more complex &amp; like to overfit</li> <li>a smaller value results in simpler models, which can lead to underfitting</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create the pipeline
</span><span class="n">xgb_pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">imputer</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">bmi_calc</span><span class="sh">'</span><span class="p">,</span> <span class="nc">BMICalculator</span><span class="p">()),</span> <span class="c1"># after SimpleImputer and before StandardScaler
</span>    <span class="p">(</span><span class="sh">'</span><span class="s">scaler</span><span class="sh">'</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">xgb</span><span class="sh">'</span><span class="p">,</span> <span class="n">xgb</span><span class="p">.</span><span class="nc">XGBRegressor</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Define the parameter grid
</span><span class="n">xgb_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">xgb__n_estimators</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">xgb__learning_rate</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">xgb__max_depth</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Initialize GridSearchCV
</span><span class="n">xgb_cv</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span> <span class="o">=</span> <span class="n">xgb_pipeline</span><span class="p">,</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">xgb_params</span><span class="p">,</span>
    <span class="n">scoring</span> <span class="o">=</span> <span class="sh">'</span><span class="s">neg_root_mean_squared_error</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="n">kf</span><span class="p">,</span>
    <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">return_train_score</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>  <span class="c1"># store training scores
</span><span class="p">)</span>

<span class="c1"># Fit the grid search to the data
</span><span class="n">xgb_cv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div> <style>#sk-container-id-3{--sklearn-color-text:#000;--sklearn-color-text-muted:#666;--sklearn-color-line:gray;--sklearn-color-unfitted-level-0:#fff5e6;--sklearn-color-unfitted-level-1:#f6e4d2;--sklearn-color-unfitted-level-2:#ffe0b3;--sklearn-color-unfitted-level-3:chocolate;--sklearn-color-fitted-level-0:#f0f8ff;--sklearn-color-fitted-level-1:#d4ebff;--sklearn-color-fitted-level-2:#b3dbfd;--sklearn-color-fitted-level-3:cornflowerblue;--sklearn-color-text-on-default-background:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,black)));--sklearn-color-background:var(--sg-background-color,var(--theme-background,var(--jp-layout-color0,white)));--sklearn-color-border-box:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,black)));--sklearn-color-icon:#696969;@media(prefers-color-scheme:dark){--sklearn-color-text-on-default-background:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,white)));--sklearn-color-background:var(--sg-background-color,var(--theme-background,var(--jp-layout-color0,#111)));--sklearn-color-border-box:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,white)));--sklearn-color-icon:#878787}}#sk-container-id-3{color:var(--sklearn-color-text)}#sk-container-id-3 pre{padding:0}#sk-container-id-3 input.sk-hidden--visually{border:0;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#sk-container-id-3 div.sk-dashed-wrapped{border:1px dashed var(--sklearn-color-line);margin:0 .4em .5em .4em;box-sizing:border-box;padding-bottom:.4em;background-color:var(--sklearn-color-background)}#sk-container-id-3 div.sk-container{display:inline-block!important;position:relative}#sk-container-id-3 div.sk-text-repr-fallback{display:none}div.sk-parallel-item,div.sk-serial,div.sk-item{background-image:linear-gradient(var(--sklearn-color-text-on-default-background),var(--sklearn-color-text-on-default-background));background-size:2px 100%;background-repeat:no-repeat;background-position:center center}#sk-container-id-3 div.sk-parallel-item::after{content:"";width:100%;border-bottom:2px solid var(--sklearn-color-text-on-default-background);flex-grow:1}#sk-container-id-3 div.sk-parallel{display:flex;align-items:stretch;justify-content:center;background-color:var(--sklearn-color-background);position:relative}#sk-container-id-3 div.sk-parallel-item{display:flex;flex-direction:column}#sk-container-id-3 div.sk-parallel-item:first-child::after{align-self:flex-end;width:50%}#sk-container-id-3 div.sk-parallel-item:last-child::after{align-self:flex-start;width:50%}#sk-container-id-3 div.sk-parallel-item:only-child::after{width:0}#sk-container-id-3 div.sk-serial{display:flex;flex-direction:column;align-items:center;background-color:var(--sklearn-color-background);padding-right:1em;padding-left:1em}#sk-container-id-3 div.sk-toggleable{background-color:var(--sklearn-color-background)}#sk-container-id-3 label.sk-toggleable__label{cursor:pointer;display:flex;width:100%;margin-bottom:0;padding:.5em;box-sizing:border-box;text-align:center;align-items:start;justify-content:space-between;gap:.5em}#sk-container-id-3 label.sk-toggleable__label .caption{font-size:.6rem;font-weight:lighter;color:var(--sklearn-color-text-muted)}#sk-container-id-3 label.sk-toggleable__label-arrow:before{content:"▸";float:left;margin-right:.25em;color:var(--sklearn-color-icon)}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before{color:var(--sklearn-color-text)}#sk-container-id-3 div.sk-toggleable__content{max-height:0;max-width:0;overflow:hidden;text-align:left;background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-3 div.sk-toggleable__content.fitted{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-3 div.sk-toggleable__content pre{margin:.2em;border-radius:.25em;color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-3 div.sk-toggleable__content.fitted pre{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content{max-height:200px;max-width:100%;overflow:auto}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before{content:"▾"}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label{color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-fitted-level-2)}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-fitted-level-2)}
#sk-container-id-3 div.sk-label label.sk-toggleable__label,#sk-container-id-3 div.sk-label label{color:var(--sklearn-color-text-on-default-background)}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label{color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted{color:var(--sklearn-color-text);background-color:var(--sklearn-color-fitted-level-2)}#sk-container-id-3 div.sk-label label{font-family:monospace;font-weight:bold;display:inline-block;line-height:1.2em}#sk-container-id-3 div.sk-label-container{text-align:center}#sk-container-id-3 div.sk-estimator{font-family:monospace;border:1px dotted var(--sklearn-color-border-box);border-radius:.25em;box-sizing:border-box;margin-bottom:.5em;background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-3 div.sk-estimator.fitted{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-3 div.sk-estimator:hover{background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-3 div.sk-estimator.fitted:hover{background-color:var(--sklearn-color-fitted-level-2)}.sk-estimator-doc-link,a:link.sk-estimator-doc-link,a:visited.sk-estimator-doc-link{float:right;font-size:smaller;line-height:1em;font-family:monospace;background-color:var(--sklearn-color-background);border-radius:1em;height:1em;width:1em;text-decoration:none!important;margin-left:.5em;text-align:center;border:var(--sklearn-color-unfitted-level-1) 1pt solid;color:var(--sklearn-color-unfitted-level-1)}.sk-estimator-doc-link.fitted,a:link.sk-estimator-doc-link.fitted,a:visited.sk-estimator-doc-link.fitted{border:var(--sklearn-color-fitted-level-1) 1pt solid;color:var(--sklearn-color-fitted-level-1)}div.sk-estimator:hover .sk-estimator-doc-link:hover,.sk-estimator-doc-link:hover,div.sk-label-container:hover .sk-estimator-doc-link:hover,.sk-estimator-doc-link:hover{background-color:var(--sklearn-color-unfitted-level-3);color:var(--sklearn-color-background);text-decoration:none}div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,.sk-estimator-doc-link.fitted:hover,div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,.sk-estimator-doc-link.fitted:hover{background-color:var(--sklearn-color-fitted-level-3);color:var(--sklearn-color-background);text-decoration:none}.sk-estimator-doc-link span{display:none;z-index:9999;position:relative;font-weight:normal;right:.2ex;padding:.5ex;margin:.5ex;width:min-content;min-width:20ex;max-width:50ex;color:var(--sklearn-color-text);box-shadow:2pt 2pt 4pt #999;background:var(--sklearn-color-unfitted-level-0);border:.5pt solid var(--sklearn-color-unfitted-level-3)}.sk-estimator-doc-link.fitted span{background:var(--sklearn-color-fitted-level-0);border:var(--sklearn-color-fitted-level-3)}.sk-estimator-doc-link:hover span{display:block}#sk-container-id-3 a.estimator_doc_link{float:right;font-size:1rem;line-height:1em;font-family:monospace;background-color:var(--sklearn-color-background);border-radius:1rem;height:1rem;width:1rem;text-decoration:none;color:var(--sklearn-color-unfitted-level-1);border:var(--sklearn-color-unfitted-level-1) 1pt solid}#sk-container-id-3 a.estimator_doc_link.fitted{border:var(--sklearn-color-fitted-level-1) 1pt solid;color:var(--sklearn-color-fitted-level-1)}#sk-container-id-3 a.estimator_doc_link:hover{background-color:var(--sklearn-color-unfitted-level-3);color:var(--sklearn-color-background);text-decoration:none}#sk-container-id-3 a.estimator_doc_link.fitted:hover{background-color:var(--sklearn-color-fitted-level-3)}</style> <div id="sk-container-id-3" class="sk-top-container"> <div class="sk-text-repr-fallback"> <pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('imputer', SimpleImputer()),
                                       ('bmi_calc', BMICalculator()),
                                       ('scaler', StandardScaler()),
                                       ('xgb',
                                        XGBRegressor(base_score=None,
                                                     booster=None,
                                                     callbacks=None,
                                                     colsample_bylevel=None,
                                                     colsample_bynode=None,
                                                     colsample_bytree=None,
                                                     device=None,
                                                     early_stopping_rounds=None,
                                                     enable...
                                                     max_leaves=None,
                                                     min_child_weight=None,
                                                     missing=nan,
                                                     monotone_constraints=None,
                                                     multi_strategy=None,
                                                     n_estimators=None,
                                                     n_jobs=None,
                                                     num_parallel_tree=None,
                                                     random_state=None, ...))]),
             n_jobs=-1,
             param_grid={'xgb__learning_rate': [0.01, 0.1, 0.2],
                         'xgb__max_depth': [1, 2, 3],
                         'xgb__n_estimators': [20, 25, 50]},
             return_train_score=True, scoring='neg_root_mean_squared_error')</pre> <b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b> </div> <div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"> <div class="sk-label-container"><div class="sk-label fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-13" type="checkbox"><label for="sk-estimator-id-13" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>GridSearchCV</div></div> <div> <a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span> </div></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('imputer', SimpleImputer()),
                                       ('bmi_calc', BMICalculator()),
                                       ('scaler', StandardScaler()),
                                       ('xgb',
                                        XGBRegressor(base_score=None,
                                                     booster=None,
                                                     callbacks=None,
                                                     colsample_bylevel=None,
                                                     colsample_bynode=None,
                                                     colsample_bytree=None,
                                                     device=None,
                                                     early_stopping_rounds=None,
                                                     enable...
                                                     max_leaves=None,
                                                     min_child_weight=None,
                                                     missing=nan,
                                                     monotone_constraints=None,
                                                     multi_strategy=None,
                                                     n_estimators=None,
                                                     n_jobs=None,
                                                     num_parallel_tree=None,
                                                     random_state=None, ...))]),
             n_jobs=-1,
             param_grid={'xgb__learning_rate': [0.01, 0.1, 0.2],
                         'xgb__max_depth': [1, 2, 3],
                         'xgb__n_estimators': [20, 25, 50]},
             return_train_score=True, scoring='neg_root_mean_squared_error')</pre></div> </div></div> <div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"> <div class="sk-label-container"><div class="sk-label fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-14" type="checkbox"><label for="sk-estimator-id-14" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>best_estimator_: Pipeline</div></div></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('imputer', SimpleImputer()), ('bmi_calc', BMICalculator()),
                ('scaler', StandardScaler()),
                ('xgb',
                 XGBRegressor(base_score=None, booster=None, callbacks=None,
                              colsample_bylevel=None, colsample_bynode=None,
                              colsample_bytree=None, device=None,
                              early_stopping_rounds=None,
                              enable_categorical=False, eval_metric=None,
                              feature_types=None, gamma=None, grow_policy=None,
                              importance_type=None,
                              interaction_constraints=None, learning_rate=0.2,
                              max_bin=None, max_cat_threshold=None,
                              max_cat_to_onehot=None, max_delta_step=None,
                              max_depth=2, max_leaves=None,
                              min_child_weight=None, missing=nan,
                              monotone_constraints=None, multi_strategy=None,
                              n_estimators=50, n_jobs=None,
                              num_parallel_tree=None, random_state=None, ...))])</pre></div> </div></div> <div class="sk-serial"><div class="sk-item"><div class="sk-serial"> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-15" type="checkbox"><label for="sk-estimator-id-15" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>SimpleImputer</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html">?<span>Documentation for SimpleImputer</span></a></div></label><div class="sk-toggleable__content fitted"><pre>SimpleImputer()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-16" type="checkbox"><label for="sk-estimator-id-16" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>BMICalculator</div></div></label><div class="sk-toggleable__content fitted"><pre>BMICalculator()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-17" type="checkbox"><label for="sk-estimator-id-17" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>StandardScaler</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></div></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-18" type="checkbox"><label for="sk-estimator-id-18" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>XGBRegressor</div></div></label><div class="sk-toggleable__content fitted"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, device=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=0.2, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=2, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             multi_strategy=None, n_estimators=50, n_jobs=None,
             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div> </div></div></div> </div></div></div> </div></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgb_cv</span><span class="p">.</span><span class="n">best_params_</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'xgb__learning_rate': 0.2, 'xgb__max_depth': 2, 'xgb__n_estimators': 50}
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">best_xgb_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">xgb_cv</span><span class="p">.</span><span class="n">best_score_</span>  <span class="c1"># convert back to MSE
</span><span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb_cv</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="c1"># print optimization results
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">XGB: </span><span class="se">\n</span><span class="s"> Best parameters:</span><span class="se">\n</span><span class="si">{</span><span class="n">xgb_cv</span><span class="p">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s"> </span><span class="se">\n\n</span><span class="s"> RMSE: **</span><span class="si">{</span><span class="n">best_xgb_score</span><span class="si">}</span><span class="s">**</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>XGB: 
 Best parameters:
{'xgb__learning_rate': 0.2, 'xgb__max_depth': 2, 'xgb__n_estimators': 50} 

 RMSE: **3.2180051078575618**
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">From our 5-fold cross-validation, the XGBOost model</span><span class="sh">'</span><span class="s">s predictions for Cycle_3 were on average </span><span class="si">{</span><span class="n">best_xgb_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> days off from the actual lengths.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>From our 5-fold cross-validation, the XGBOost model's predictions for Cycle_3 were on average 3.22 days off from the actual lengths.
</code></pre></div></div> <p>Based on our hyperparameter tuning results, we can see that:</p> <p>A <strong>learning_rate</strong> value of 0.2 indicates that the model will likely have long-term learning. Additionally, as mentioned previously, smaller (aka slower) learning rates resist overfitting more. From our ElasticNet model, we gleaned that overfitting will likely be an issue with our dataset due to its small size. A small learning rate of 0.2 further supports the theory that the most optimal models are ones that reduce overfitting.</p> <p>A <strong>max_depth</strong> value of 1 additionally supports this notion, as smaller values result in simpler models that are less prone to overfitting.</p> <p>Finally, a <strong>n_estimators</strong> value of 25 is lower than typical which helps reduce overfitting. A common value for this hyperparameter is between 100 and 1000, which is much larger than our optimal value of 25.</p> <p>Overall, our best-performing cross-validated XGBoost model took numerous steps to reduce the issue of overfitting that is likely present in our data.</p> <h2 id="knn">KNN</h2> <p>k-Nearest Neighbour models, also known as KNN models, is an algorithm that makes predictions for the target variable by finding the “k” nearest data points to a given input and averaging their target values.</p> <p>It is the responsibility of the person making the model (that’s us!) to choose the number of nearest neighbours “k” that will be used to make predictions.</p> <p>There are additionally other hyperparameters that we can tune to find the most optimal KNN model.</p> <p><strong>Hyperparameters to tune</strong></p> <p><code class="language-plaintext highlighter-rouge">n_neighbours</code> = the number of nearest neighbours to make predictions from</p> <ul> <li>a small k (ie., 1 or 3) may lead to noisy predictions (overfitting)</li> <li>a large k may lead to overly smoothed predictions (underfitting)</li> </ul> <p><code class="language-plaintext highlighter-rouge">metric</code> = a distance metric that is used to measure the similarity between data points.</p> <ul> <li>euclidean = calculates the <em>straight-line</em> distance between two data points</li> <li>manhattan = calculates the distance by summing the absolute differences between the coordinates of two poins. <ul> <li>useful for grid-based data or when the distance is measured along axes</li> <li>less sensitive to outliers than euclidean distance</li> </ul> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">knn_pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">imputer</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">bmi_calc</span><span class="sh">'</span><span class="p">,</span> <span class="nc">BMICalculator</span><span class="p">()),</span> <span class="c1"># after SimpleImputer and before StandardScaler
</span>    <span class="p">(</span><span class="sh">"</span><span class="s">scaler</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">knn</span><span class="sh">'</span><span class="p">,</span> <span class="nc">KNeighborsRegressor</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Define the parameter grid for KNN
</span><span class="n">knn_param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">knn__n_neighbors</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">2</span><span class="p">)],</span> <span class="c1"># dictionary key, needs to be double underscored to be understood
</span>    <span class="sh">'</span><span class="s">knn__metric</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">euclidean</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">manhattan</span><span class="sh">'</span><span class="p">],</span>  <span class="c1"># weighting scheme for neighbors
</span><span class="p">}</span>

<span class="c1"># Initialize GridSearchCV for KNN
</span><span class="n">knn_cv</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span>
    <span class="n">knn_pipeline</span><span class="p">,</span>
    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">knn_param_grid</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span>  <span class="c1"># using the predefined KFold object
</span>    <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">neg_root_mean_squared_error</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span>
<span class="p">)</span>

<span class="c1"># Fit the grid search to the training data
</span><span class="n">knn_cv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div> <style>#sk-container-id-4{--sklearn-color-text:#000;--sklearn-color-text-muted:#666;--sklearn-color-line:gray;--sklearn-color-unfitted-level-0:#fff5e6;--sklearn-color-unfitted-level-1:#f6e4d2;--sklearn-color-unfitted-level-2:#ffe0b3;--sklearn-color-unfitted-level-3:chocolate;--sklearn-color-fitted-level-0:#f0f8ff;--sklearn-color-fitted-level-1:#d4ebff;--sklearn-color-fitted-level-2:#b3dbfd;--sklearn-color-fitted-level-3:cornflowerblue;--sklearn-color-text-on-default-background:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,black)));--sklearn-color-background:var(--sg-background-color,var(--theme-background,var(--jp-layout-color0,white)));--sklearn-color-border-box:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,black)));--sklearn-color-icon:#696969;@media(prefers-color-scheme:dark){--sklearn-color-text-on-default-background:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,white)));--sklearn-color-background:var(--sg-background-color,var(--theme-background,var(--jp-layout-color0,#111)));--sklearn-color-border-box:var(--sg-text-color,var(--theme-code-foreground,var(--jp-content-font-color1,white)));--sklearn-color-icon:#878787}}#sk-container-id-4{color:var(--sklearn-color-text)}#sk-container-id-4 pre{padding:0}#sk-container-id-4 input.sk-hidden--visually{border:0;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#sk-container-id-4 div.sk-dashed-wrapped{border:1px dashed var(--sklearn-color-line);margin:0 .4em .5em .4em;box-sizing:border-box;padding-bottom:.4em;background-color:var(--sklearn-color-background)}#sk-container-id-4 div.sk-container{display:inline-block!important;position:relative}#sk-container-id-4 div.sk-text-repr-fallback{display:none}div.sk-parallel-item,div.sk-serial,div.sk-item{background-image:linear-gradient(var(--sklearn-color-text-on-default-background),var(--sklearn-color-text-on-default-background));background-size:2px 100%;background-repeat:no-repeat;background-position:center center}#sk-container-id-4 div.sk-parallel-item::after{content:"";width:100%;border-bottom:2px solid var(--sklearn-color-text-on-default-background);flex-grow:1}#sk-container-id-4 div.sk-parallel{display:flex;align-items:stretch;justify-content:center;background-color:var(--sklearn-color-background);position:relative}#sk-container-id-4 div.sk-parallel-item{display:flex;flex-direction:column}#sk-container-id-4 div.sk-parallel-item:first-child::after{align-self:flex-end;width:50%}#sk-container-id-4 div.sk-parallel-item:last-child::after{align-self:flex-start;width:50%}#sk-container-id-4 div.sk-parallel-item:only-child::after{width:0}#sk-container-id-4 div.sk-serial{display:flex;flex-direction:column;align-items:center;background-color:var(--sklearn-color-background);padding-right:1em;padding-left:1em}#sk-container-id-4 div.sk-toggleable{background-color:var(--sklearn-color-background)}#sk-container-id-4 label.sk-toggleable__label{cursor:pointer;display:flex;width:100%;margin-bottom:0;padding:.5em;box-sizing:border-box;text-align:center;align-items:start;justify-content:space-between;gap:.5em}#sk-container-id-4 label.sk-toggleable__label .caption{font-size:.6rem;font-weight:lighter;color:var(--sklearn-color-text-muted)}#sk-container-id-4 label.sk-toggleable__label-arrow:before{content:"▸";float:left;margin-right:.25em;color:var(--sklearn-color-icon)}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before{color:var(--sklearn-color-text)}#sk-container-id-4 div.sk-toggleable__content{max-height:0;max-width:0;overflow:hidden;text-align:left;background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-4 div.sk-toggleable__content.fitted{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-4 div.sk-toggleable__content pre{margin:.2em;border-radius:.25em;color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-4 div.sk-toggleable__content.fitted pre{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content{max-height:200px;max-width:100%;overflow:auto}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before{content:"▾"}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label{color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-fitted-level-2)}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label{background-color:var(--sklearn-color-fitted-level-2)}
#sk-container-id-4 div.sk-label label.sk-toggleable__label,#sk-container-id-4 div.sk-label label{color:var(--sklearn-color-text-on-default-background)}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label{color:var(--sklearn-color-text);background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted{color:var(--sklearn-color-text);background-color:var(--sklearn-color-fitted-level-2)}#sk-container-id-4 div.sk-label label{font-family:monospace;font-weight:bold;display:inline-block;line-height:1.2em}#sk-container-id-4 div.sk-label-container{text-align:center}#sk-container-id-4 div.sk-estimator{font-family:monospace;border:1px dotted var(--sklearn-color-border-box);border-radius:.25em;box-sizing:border-box;margin-bottom:.5em;background-color:var(--sklearn-color-unfitted-level-0)}#sk-container-id-4 div.sk-estimator.fitted{background-color:var(--sklearn-color-fitted-level-0)}#sk-container-id-4 div.sk-estimator:hover{background-color:var(--sklearn-color-unfitted-level-2)}#sk-container-id-4 div.sk-estimator.fitted:hover{background-color:var(--sklearn-color-fitted-level-2)}.sk-estimator-doc-link,a:link.sk-estimator-doc-link,a:visited.sk-estimator-doc-link{float:right;font-size:smaller;line-height:1em;font-family:monospace;background-color:var(--sklearn-color-background);border-radius:1em;height:1em;width:1em;text-decoration:none!important;margin-left:.5em;text-align:center;border:var(--sklearn-color-unfitted-level-1) 1pt solid;color:var(--sklearn-color-unfitted-level-1)}.sk-estimator-doc-link.fitted,a:link.sk-estimator-doc-link.fitted,a:visited.sk-estimator-doc-link.fitted{border:var(--sklearn-color-fitted-level-1) 1pt solid;color:var(--sklearn-color-fitted-level-1)}div.sk-estimator:hover .sk-estimator-doc-link:hover,.sk-estimator-doc-link:hover,div.sk-label-container:hover .sk-estimator-doc-link:hover,.sk-estimator-doc-link:hover{background-color:var(--sklearn-color-unfitted-level-3);color:var(--sklearn-color-background);text-decoration:none}div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,.sk-estimator-doc-link.fitted:hover,div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,.sk-estimator-doc-link.fitted:hover{background-color:var(--sklearn-color-fitted-level-3);color:var(--sklearn-color-background);text-decoration:none}.sk-estimator-doc-link span{display:none;z-index:9999;position:relative;font-weight:normal;right:.2ex;padding:.5ex;margin:.5ex;width:min-content;min-width:20ex;max-width:50ex;color:var(--sklearn-color-text);box-shadow:2pt 2pt 4pt #999;background:var(--sklearn-color-unfitted-level-0);border:.5pt solid var(--sklearn-color-unfitted-level-3)}.sk-estimator-doc-link.fitted span{background:var(--sklearn-color-fitted-level-0);border:var(--sklearn-color-fitted-level-3)}.sk-estimator-doc-link:hover span{display:block}#sk-container-id-4 a.estimator_doc_link{float:right;font-size:1rem;line-height:1em;font-family:monospace;background-color:var(--sklearn-color-background);border-radius:1rem;height:1rem;width:1rem;text-decoration:none;color:var(--sklearn-color-unfitted-level-1);border:var(--sklearn-color-unfitted-level-1) 1pt solid}#sk-container-id-4 a.estimator_doc_link.fitted{border:var(--sklearn-color-fitted-level-1) 1pt solid;color:var(--sklearn-color-fitted-level-1)}#sk-container-id-4 a.estimator_doc_link:hover{background-color:var(--sklearn-color-unfitted-level-3);color:var(--sklearn-color-background);text-decoration:none}#sk-container-id-4 a.estimator_doc_link.fitted:hover{background-color:var(--sklearn-color-fitted-level-3)}</style> <div id="sk-container-id-4" class="sk-top-container"> <div class="sk-text-repr-fallback"> <pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('imputer', SimpleImputer()),
                                       ('bmi_calc', BMICalculator()),
                                       ('scaler', StandardScaler()),
                                       ('knn', KNeighborsRegressor())]),
             n_jobs=-1,
             param_grid={'knn__metric': ['euclidean', 'manhattan'],
                         'knn__n_neighbors': [2, 4, 6, 8, 10, 12, 14, 16, 18,
                                              20, 22, 24, 26, 28, 30, 32, 34,
                                              36, 38]},
             return_train_score=True, scoring='neg_root_mean_squared_error')</pre> <b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b> </div> <div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"> <div class="sk-label-container"><div class="sk-label fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-19" type="checkbox"><label for="sk-estimator-id-19" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>GridSearchCV</div></div> <div> <a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span> </div></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[('imputer', SimpleImputer()),
                                       ('bmi_calc', BMICalculator()),
                                       ('scaler', StandardScaler()),
                                       ('knn', KNeighborsRegressor())]),
             n_jobs=-1,
             param_grid={'knn__metric': ['euclidean', 'manhattan'],
                         'knn__n_neighbors': [2, 4, 6, 8, 10, 12, 14, 16, 18,
                                              20, 22, 24, 26, 28, 30, 32, 34,
                                              36, 38]},
             return_train_score=True, scoring='neg_root_mean_squared_error')</pre></div> </div></div> <div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"> <div class="sk-label-container"><div class="sk-label fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-20" type="checkbox"><label for="sk-estimator-id-20" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>best_estimator_: Pipeline</div></div></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[('imputer', SimpleImputer()), ('bmi_calc', BMICalculator()),
                ('scaler', StandardScaler()),
                ('knn',
                 KNeighborsRegressor(metric='manhattan', n_neighbors=18))])</pre></div> </div></div> <div class="sk-serial"><div class="sk-item"><div class="sk-serial"> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-21" type="checkbox"><label for="sk-estimator-id-21" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>SimpleImputer</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.impute.SimpleImputer.html">?<span>Documentation for SimpleImputer</span></a></div></label><div class="sk-toggleable__content fitted"><pre>SimpleImputer()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-22" type="checkbox"><label for="sk-estimator-id-22" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>BMICalculator</div></div></label><div class="sk-toggleable__content fitted"><pre>BMICalculator()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-23" type="checkbox"><label for="sk-estimator-id-23" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>StandardScaler</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></div></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div> <div class="sk-item"><div class="sk-estimator fitted sk-toggleable"> <input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-24" type="checkbox"><label for="sk-estimator-id-24" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>KNeighborsRegressor</div></div> <div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsRegressor.html">?<span>Documentation for KNeighborsRegressor</span></a></div></label><div class="sk-toggleable__content fitted"><pre>KNeighborsRegressor(metric='manhattan', n_neighbors=18)</pre></div> </div></div> </div></div></div> </div></div></div> </div></div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get the best score and estimator
</span><span class="n">best_knn_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">knn_cv</span><span class="p">.</span><span class="n">best_score_</span>
<span class="n">knn_model</span> <span class="o">=</span> <span class="n">knn_cv</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="c1"># print optimization results
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">KNN: </span><span class="se">\n</span><span class="s">Best parameters:</span><span class="se">\n</span><span class="si">{</span><span class="n">knn_cv</span><span class="p">.</span><span class="n">best_params_</span><span class="si">}</span><span class="se">\n\n</span><span class="s">RMSE: </span><span class="si">{</span><span class="n">best_knn_score</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>KNN: 
Best parameters:
{'knn__metric': 'manhattan', 'knn__n_neighbors': 18}

RMSE: 3.238150776096615
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">From our 5-fold cross-validation, the KNN model</span><span class="sh">'</span><span class="s">s predictions for Cycle_3 were on average </span><span class="si">{</span><span class="n">best_knn_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> days off from the actual lengths.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>From our 5-fold cross-validation, the KNN model's predictions for Cycle_3 were on average 3.24 days off from the actual lengths.
</code></pre></div></div> <p>From our hyperparameter tuning results, we can see that:</p> <p>A <strong>distance metric</strong> of manhattan indicates that the most optimal model is one that is robust to outliers, since manhattan is less sensitive to outliers than euclidean.</p> <p>A <strong>n_neighbours</strong> value of 18 is relatively small compared to the maximum number of 40 neighbours that it could have taken. A small k value is more prone to overfitting than a large k value, so it is surpising that the most optimal model has such a relatively low k value. KNN models are pretty sensitive to overiffting as well, so this finding goes against our previous theory of there being a risk of overfitting in our data.</p> <p>However, a k value of 18 is still much higher than 1 or 2, and is just about the middle value in the range of 2 to 39 that we supplised the cross-validated model. So, 18 neighbours may in actuality be the perfect balance between overfitting and underfitting.</p> <p>Let’s visualise the GridSearchCV results using a heatmap.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Extract the results
</span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">knn_cv</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">)</span>

<span class="c1"># Convert scores from negative to positive RMSE
</span><span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">positive_rmse</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">results</span><span class="p">[</span><span class="sh">'</span><span class="s">mean_test_score</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># Create a pivot table for the heatmap
</span><span class="n">pivot_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">pivot_table</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">results</span><span class="p">,</span>
    <span class="n">values</span><span class="o">=</span><span class="sh">'</span><span class="s">positive_rmse</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="sh">'</span><span class="s">param_knn__n_neighbors</span><span class="sh">'</span><span class="p">,</span>  <span class="c1"># k values on y-axis
</span>    <span class="n">columns</span><span class="o">=</span><span class="sh">'</span><span class="s">param_knn__metric</span><span class="sh">'</span><span class="p">,</span>     <span class="c1"># distance metric on x-axis
</span><span class="p">)</span>

<span class="c1"># Create the plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span>
    <span class="n">pivot_df</span><span class="p">,</span>
    <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">,.3f</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray_r</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
    <span class="n">vmin</span> <span class="o">=</span> <span class="mf">3.163</span><span class="p">,</span>
    <span class="n">vmax</span> <span class="o">=</span> <span class="mf">3.760</span><span class="p">,</span>
    <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">RMSE (days)</span><span class="sh">'</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Set title and labels
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">KNN Regression: RMSE by Distance Metric and Number of Neighbors</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Distance Metric</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Number of Neighbors (k)</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># highlight best cell in red box
# ------------------------
# Get location of min RMSE
</span><span class="n">min_val</span> <span class="o">=</span> <span class="n">pivot_df</span><span class="p">.</span><span class="nf">min</span><span class="p">().</span><span class="nf">min</span><span class="p">()</span>
<span class="n">min_coords</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">pivot_df</span> <span class="o">==</span> <span class="n">min_val</span><span class="p">)</span>
<span class="n">row_idx</span> <span class="o">=</span> <span class="n">min_coords</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">col_idx</span> <span class="o">=</span> <span class="n">min_coords</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Draw rectangle (box) around the cell
</span><span class="n">ax</span><span class="p">.</span><span class="nf">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="nc">Rectangle</span><span class="p">(</span>
    <span class="p">(</span><span class="n">col_idx</span><span class="p">,</span> <span class="n">row_idx</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span>
<span class="p">))</span>

<span class="c1"># Add note about the best parameters
</span><span class="n">best_params</span> <span class="o">=</span> <span class="n">knn_cv</span><span class="p">.</span><span class="n">best_params_</span>
<span class="n">best_rmse</span> <span class="o">=</span> <span class="o">-</span><span class="n">knn_cv</span><span class="p">.</span><span class="n">best_score_</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figtext</span><span class="p">(</span>
    <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="sa">f</span><span class="sh">"</span><span class="s">Best parameters: k=</span><span class="si">{</span><span class="n">best_params</span><span class="p">[</span><span class="sh">'</span><span class="s">knn__n_neighbors</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">, metric=</span><span class="si">{</span><span class="n">best_params</span><span class="p">[</span><span class="sh">'</span><span class="s">knn__metric</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s"> with RMSE: </span><span class="si">{</span><span class="n">best_rmse</span><span class="si">:</span><span class="p">,.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">ha</span><span class="o">=</span><span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span>
<span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <p><img src="ML_final_project_files/ML_final_project_149_0.png" alt="png"></p> <p>From the plot, we can see that there isn’t a whole lot of variation in the RMSE cross-validation score for each hyperparameter combination. There is only about a 0.60 difference between the worst performing and best preforming KNN model.</p> <p>However, overall, k values in the middle of the range of possible values we supplied have better RMSE scores than K values in the lowest and highest ranges.</p> <p>Additionally, besides a few values at the highest possible number of neighbours, models with the manhattan distance metric performed better overall in cross-validation than models with the euclidean distance metric.</p> <h1 id="model-comparison">Model comparison</h1> <h2 id="test-set-performance">test set performance</h2> <p>Now that we’ve found the optimal parameters for all our models with cross-validation, we will fit each model using all of the training set and use the test set as the final evaluation for how each model performs.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a dictionary to store the best models
</span><span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">:</span> <span class="n">linear_model</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">elasticnet</span><span class="sh">'</span><span class="p">:</span> <span class="n">elasticnet_model</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">xgboost</span><span class="sh">'</span><span class="p">:</span> <span class="n">xgb_model</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">knn</span><span class="sh">'</span><span class="p">:</span> <span class="n">knn_model</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Evaluate the best models and print results
</span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
    <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">rmse</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: RMSE = </span><span class="si">{</span><span class="n">rmse</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Find the best-performing model based on RMSE
</span><span class="n">best_model_name</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">results</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">best_model_name</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="se">\n</span><span class="s">Best Model: </span><span class="si">{</span><span class="n">best_model_name</span><span class="si">}</span><span class="s"> with RMSE = </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="n">best_model_name</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>linear: RMSE = 3.0059
elasticnet: RMSE = 3.0024
xgboost: RMSE = 2.9943
knn: RMSE = 2.9979

Best Model: xgboost with RMSE = 2.9943
</code></pre></div></div> <p>As you can see, our XGBoost model performed the best on the test set of all the other models, with an RMSE of about 3.12 days.</p> <p>Our simple linear regression model, on the other hand, performed the worst among all the models. Thus, we can confirm that our ElasticNet, XGBoost, and KNN models all perform better than a simple linear regression model.</p> <p>Overall, though, all four of our models have test RMSEs that are fairly simllar to each other, with little variance.</p> <p>Close final test scores across different machine learning algorithms can be due to insufficient data or overfititng, both of which are issues we have run into already. Even seemingly different models can converge to similar performance if they are not complex enough to capture the subtle nuances that exist in the data. These underlying problems can make it difficult for any single algorithm to achieve a significant advantage.</p> <p>We should further evaluate each model based on overfitting versus underfitting, bias versus variance tradeoff, and flexibility and interpretability to see how prominent these issues are.</p> <h2 id="evaluating-overfitting">Evaluating overfitting</h2> <p>In order to determine which model is the best fit, we can compare the differences between the training RMSE and test RMSE of the two models.</p> <p>In the case of RMSE, when a model yields a small training RMSE but a very large test RMSE, we are said to be overfitting the data.</p> <p>The testing set RMSE will be very large because the supposed patterns that the model found in the training set does not exist in the testing set.</p> <p>The model with the smallest difference will indicate that it has a stronger fit and is also at less risk for overfitting.</p> <p>Let’s go ahead and calculate the differences between the testing and training RMSEs of each of our models.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">:</span> <span class="n">linear_model</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">elasticnet</span><span class="sh">'</span><span class="p">:</span> <span class="n">elasticnet_model</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">xgboost</span><span class="sh">'</span><span class="p">:</span> <span class="n">xgb_model</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">knn</span><span class="sh">'</span><span class="p">:</span> <span class="n">knn_model</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># calculate the y_pred for train and test sets
</span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">rmse_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">))</span>
    <span class="n">rmse_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">))</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">rmse_test</span> <span class="o">-</span> <span class="n">rmse_train</span>
    <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">rmse_train</span><span class="p">,</span> <span class="n">rmse_test</span><span class="p">,</span> <span class="n">diff</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">: Train RMSE = </span><span class="si">{</span><span class="n">rmse_train</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Test RMSE = </span><span class="si">{</span><span class="n">rmse_test</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, Difference = </span><span class="si">{</span><span class="n">diff</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>linear: Train RMSE = 3.2624, Test RMSE = 3.0059, Difference = -0.2565
elasticnet: Train RMSE = 3.2669, Test RMSE = 3.0024, Difference = -0.2645
xgboost: Train RMSE = 2.8909, Test RMSE = 2.9943, Difference = 0.1034
knn: Train RMSE = 3.0599, Test RMSE = 2.9979, Difference = -0.0620
</code></pre></div></div> <p>Regarding overfitting concerns, a generally accepted rule of thumb is that if the difference between the training and test set performance is more than 5-10%, it suggests overfitting.</p> <p>The model that performed better better on the training set than the test set to the largest degree is our KNN model, with a 0.1326 difference. This translates to about a 4.23% difference, which is very close to our threshold of 5-10%. This suggests that our KNN model is overfitting. This is in accordance with our previous statement about outliers and KNN models. KNN models can be sensitive to outliers, as they can lead to amplified and potentially inaccurate decision boundaries. Thus, overall, we can state with pretty high confidence that our final KNN model is overfitting.</p> <p>The rest of our models: simple linear regression, ElasticNet, and XGBoost, do not have have a better performing training set compared to the test set. If anything, our more simple models (linear and ElasticNet) are more prone to underfitting than overfitting. These models assume a linear relationship and predict the data in a straight line format, which may not always be the case in real-world data. Since these models are too simple, it cannot learn the patterns in the data, leading to underfitting.</p> <p>A good sign of underfitting is when performance on both the training and set set are poor. Compared to our XGBoost model, these models performed worst on both the training and set sets.</p> <p>Thus, choosing XGBOost as our final model is still the right move. Not only does it have the best test set performance, XGBoost is impervious to outliers, noisy data, etc., and thus is the best model to use for our data.</p> <h2 id="bias-variance-tradeoff">Bias-variance tradeoff</h2> <p>The <strong>bias-variance tradeoff</strong> is the delicate balance between two sources of error in a predictive model: bias and variance.</p> <p><strong>Bias</strong> represents the error due to overly simplistic assumptions in the learning algorithm. It is the difference between the prediction of the values by the machine learning model and the actual values.</p> <p>Conversely, <strong>variance</strong> reflects the model’s sensitivity to small fluctuations in the training data.</p> <p>A model that exhibits small variance and high bias will underfit the target, whereas a model with high variance and low bias will overfit the target.</p> <p>From the previous section, we determined that our KNN model is very close to the 5-10% threshold for overfitting. Thus, it can be concluded that this model likely has high variance and low bias.</p> <p>Additionally, our linear regression and ElasticNet models are likely too simple to accurately capture the complex patterns in our dataset. Thus, they likely have low variance and high bias.</p> <p>Overall, it seems like our XGBoost model achieved the bias-variance tradeoff the most out of all the algorithms. It has low bias and low variance, meaning it is able to capture the underlying patterns in our data and is not too sensitive to changes in the training data. It has the right level of complexity to minimize both vias and variance, achieving accurate generalizations to new unseen data.</p> <h2 id="flexibility-vs-interpretability">Flexibility vs interpretability</h2> <p>A <strong>flexible</strong> model can adapt to complex patterns in the data, leading to more accurate predictions, but they are often harder to understand and explain. Flexibility defines how <em>restrictive</em> the model is.</p> <p><strong>Interpretable</strong> models, on the other hand, are easier to understand and explain, but may be less flexible, more rigid, and less accurate.</p> <p>Our simple linear regression model is known for its interpretability. In fact, linear regression models are one of the first regression models taught in statistics classes due to their simplicity and use case beyond just the world of machine learning. However, by being interpretable, it sacrifices flexibility; as mentioned previously, linear regression models are unable to capture complex, non-linear relationships.</p> <p>ElasticNet models offer a good balance between interpretability and flexibility. The balance that they give to both Lasso and Ridge regression methods allow them to handle complex relationships and multicollinearity. Given that it is also a linear regression technique, it also has high interpretability.</p> <p>Similarly, KNN models are very interpretable. Its methods are easy to understand and explain–it simply relies on the proximity of nearest neighbours in the data to make predictions.Its ability to handle various data types and the customization in distance metrics and ‘k’ value makes it suitable for a wide range of problems, thereby having high flexibility.</p> <p>Lastly, XGBoost is considered to have very good flexibility. It’s immunity to outliers and noisy data, and the ability for its trees to “learn” from previous trees results in accurate predictions and adaptability. However, it is generally considered less interpretable than the other models we used. It is often considered a “black box” model due to the challenge of understanding its internal workings.</p> <h1 id="final-thoughts">Final thoughts</h1> <p>As you can see, our XGBoost model performed the best on the test set of all the other models, with an RMSE of about 3.12 days.</p> <p>Given that, as mentioned previously, cycle lengths naturally vary by about 5 days month to month, a model whose predictions are on average only 3 days off from actual lengths is a strong model. Since cycle lengths are already not an exact science, and no model can predit with 100% accuracy the <em>exact</em> date someone’s next period will arrive, an average error rate of 3 days is very good.</p> <p>We previously explored whether we should remove outliers from our data or not, and determined that we should wait until we find our optimal model before deciging. Since XGBoost models are generally robust to outliers, and we determined that the outliers present in our data are not implausible but just due to natural fluctuations in the population, we can confidently decide to <em>not</em> transform or remove the outliers in any way.</p> <p>Overall, XGBoost models are resistant to outliers, noisy data, and overfitting, all of which are concerns with our small dataset. Through comparing our models, we were able to determine that our XGBoost model was the least prone to overfitting and achieved the bias-variance tradeoff to the highest degree. Despite some concern regarding the interpretability of the model, since prediction is our main interest in the current project, interpretability is not that much of a concern, and we should use the most flexible model that is usually the most accurate.</p> <p>We will use this model to make our predictor tool web app!</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Kai Holl. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>